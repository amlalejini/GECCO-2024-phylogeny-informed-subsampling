# Program synthesis experiments

```{r}
experiment_slug <- "2023-12-30-psynth"

working_directory <- paste0(
  "experiments/",
  experiment_slug,
  "/analysis/"
)

if (exists("bookdown_wd_prefix")) {
  working_directory <- paste0(
    bookdown_wd_prefix,
    working_directory
  )
}
```

## Dependencies

```{r}
library(tidyverse)
library(ggplot2)
library(cowplot)
library(RColorBrewer)
library(khroma)
library(rstatix)
library(knitr)
library(kableExtra)
source("https://gist.githubusercontent.com/benmarwick/2a1bb0133ff568cbe28d/raw/fb53bd97121f7f9ce947837ef1a4c65a73bffb3f/geom_flat_violin.R")
```

```{r}
print(version)
```

## Setup

```{r}
# Configure our default graphing theme
theme_set(theme_cowplot())
# Create a directory to store plots
plot_directory <- paste0(working_directory, "plots/")
dir.create(plot_directory, showWarnings=FALSE)
```

### Load summary data

```{r}
summary_data_loc <- paste0(working_directory, "data/aggregate.csv")
summary_data <- read_csv(summary_data_loc)

summary_data <- summary_data %>%
  mutate(
    eval_mode_row = case_when(
      EVAL_MODE == "full" & TEST_DOWNSAMPLE_RATE == "1" ~ "down-sample",
      EVAL_MODE == "full" & NUM_COHORTS == "1" ~ "cohort",
      .default = EVAL_MODE
    ),
    evals_per_gen = case_when(
      EVAL_MODE == "cohort" ~ 1.0 / NUM_COHORTS,
      EVAL_MODE == "down-sample" ~ TEST_DOWNSAMPLE_RATE,
      EVAL_MODE == "indiv-rand-sample" ~ TEST_DOWNSAMPLE_RATE,
      EVAL_MODE == "phylo-informed-sample" ~ TEST_DOWNSAMPLE_RATE,
      EVAL_MODE == "full" ~ 1.0
    ),
    EVAL_FIT_EST_MODE = case_when(
      EVAL_FIT_EST_MODE == "ancestor-opt" ~ "ancestor",
      EVAL_FIT_EST_MODE == "relative-opt" ~ "relative",
      .default = EVAL_FIT_EST_MODE
    ),
    est_mode_with_depth = paste(
      EVAL_FIT_EST_MODE,
      EVAL_MAX_PHYLO_SEARCH_DEPTH,
      sep = "-"
    ),
    eval_mode_est_mode_depth = paste(
      EVAL_MODE,
      EVAL_FIT_EST_MODE,
      EVAL_MAX_PHYLO_SEARCH_DEPTH,
      sep = "-"
    ),
    .keep = "all"
  ) %>%
  mutate(
    eval_label = case_when(
      # Clean up down-sample label
      EVAL_MODE == "down-sample" & EVAL_FIT_EST_MODE != "none" ~ paste("down-sample", EVAL_FIT_EST_MODE, sep="-"),
      .default = EVAL_MODE
    ),
  ) %>%
  mutate(
    evals_per_gen = as.factor(evals_per_gen),
    est_mode_with_depth = as.factor(est_mode_with_depth),
    eval_mode_est_mode_depth = as.factor(eval_mode_est_mode_depth),
    EVAL_MAX_PHYLO_SEARCH_DEPTH = as.factor(EVAL_MAX_PHYLO_SEARCH_DEPTH),
    PROBLEM = as.factor(PROBLEM),
    SELECTION = as.factor(SELECTION),
    EVAL_MODE = as.factor(EVAL_MODE),
    NUM_COHORTS = as.factor(NUM_COHORTS),
    TEST_DOWNSAMPLE_RATE = as.factor(TEST_DOWNSAMPLE_RATE),
    EVAL_FIT_EST_MODE = factor(
      EVAL_FIT_EST_MODE,
      levels = c(
        "none",
        "ancestor",
        "relative"
      ),
      labels = c(
        "None",
        "Ancestor",
        "Relative"
      )
    ),
    .keep = "all"
  )

solution_counts <- summary_data %>%
  group_by(
    PROBLEM,
    evals_per_gen,
    eval_mode_row,
    EVAL_FIT_EST_MODE,
    est_mode_with_depth,
    eval_mode_est_mode_depth,
    EVAL_MODE,
    eval_label,
    EVAL_MAX_PHYLO_SEARCH_DEPTH
  ) %>%
  summarize(
    solution_count = sum(found_solution == "1"),
    replicates = n(),
    no_solution_count = n() - sum(found_solution == "1")
  )
# print(solution_counts, n=208)
solution_table <- kable(solution_counts) %>%
  kable_styling(latex_options = "striped", font_size = 25)
save_kable(solution_table, paste0(plot_directory, "solution_counts_table.pdf"))
solution_table
```

```{r}
# Summarize avg num selected
# -- Not totally great because weird stuff happens when a solution is found (population collapses, etc)
ts_data_loc <- paste0(working_directory, "data/time_series.csv")
ts_data <- read_csv(ts_data_loc)

ts_data <- ts_data %>%
  mutate(
    eval_mode_row = case_when(
      EVAL_MODE == "full" & TEST_DOWNSAMPLE_RATE == "1" ~ "down-sample",
      EVAL_MODE == "full" & NUM_COHORTS == "1" ~ "cohort",
      .default = EVAL_MODE
    ),
    evals_per_gen = case_when(
      EVAL_MODE == "cohort" ~ 1.0 / NUM_COHORTS,
      EVAL_MODE == "down-sample" ~ TEST_DOWNSAMPLE_RATE,
      EVAL_MODE == "indiv-rand-sample" ~ TEST_DOWNSAMPLE_RATE,
      EVAL_MODE == "phylo-informed-sample" ~ TEST_DOWNSAMPLE_RATE,
      EVAL_MODE == "full" ~ 1.0
    ),
    EVAL_FIT_EST_MODE = case_when(
      EVAL_FIT_EST_MODE == "ancestor-opt" ~ "ancestor",
      EVAL_FIT_EST_MODE == "relative-opt" ~ "relative",
      .default = EVAL_FIT_EST_MODE
    ),
    est_mode_with_depth = paste(
      EVAL_FIT_EST_MODE,
      EVAL_MAX_PHYLO_SEARCH_DEPTH,
      sep = "-"
    ),
    eval_mode_est_mode_depth = paste(
      EVAL_MODE,
      EVAL_FIT_EST_MODE,
      EVAL_MAX_PHYLO_SEARCH_DEPTH,
      sep = "-"
    ),
    .keep = "all"
  ) %>%
  mutate(
    eval_label = case_when(
      # Clean up down-sample label
      EVAL_MODE == "down-sample" & EVAL_FIT_EST_MODE != "none" ~ paste("down-sample", EVAL_FIT_EST_MODE, sep="-"),
      .default = EVAL_MODE
    ),
  ) %>%
  mutate(
    evals_per_gen = as.factor(evals_per_gen),
    est_mode_with_depth = as.factor(est_mode_with_depth),
    eval_mode_est_mode_depth = as.factor(eval_mode_est_mode_depth),
    EVAL_MAX_PHYLO_SEARCH_DEPTH = as.factor(EVAL_MAX_PHYLO_SEARCH_DEPTH),
    PROBLEM = as.factor(PROBLEM),
    SELECTION = as.factor(SELECTION),
    EVAL_MODE = as.factor(EVAL_MODE),
    NUM_COHORTS = as.factor(NUM_COHORTS),
    TEST_DOWNSAMPLE_RATE = as.factor(TEST_DOWNSAMPLE_RATE),
    EVAL_FIT_EST_MODE = factor(
      EVAL_FIT_EST_MODE,
      levels = c(
        "none",
        "ancestor",
        "relative"
      ),
      labels = c(
        "None",
        "Ancestor",
        "Relative"
      )
    ),
    .keep = "all"
  )

ts_avgs <- ts_data %>%
  group_by(
    SEED,
    eval_label,
    evals_per_gen,
    PROBLEM
  ) %>%
  summarize(
    n = n(),
    avg_num_unique_selected = mean(num_unique_selected),
    avg_entropy_selected_ids = mean(entropy_selected_ids)
  ) %>%
  mutate(
    eval_label = as.factor(eval_label),
    evals_per_gen = as.factor(evals_per_gen),
    PROBLEM = as.factor(PROBLEM)
  )
```

## Problem-solving success statistics

```{r}
sol_stats_data <- solution_counts %>%
  filter(EVAL_MODE != "full") %>%
  ungroup() %>%
  unite(
    "grouping",
    PROBLEM,
    evals_per_gen,
    sep="_"
  ) %>%
  select(
    grouping, eval_label, solution_count, no_solution_count
  ) %>%
  mutate(
    grouping = as.factor(grouping)
  )
```

```{r}
fisher_results <- data.frame(
  comparison = character(),
  group1 = character(),
  group2 = character(),
  n = integer(),
  p = double(),
  p.adj = double(),
  p.adj.signif = character()
)

groupings <- levels(sol_stats_data$grouping)
for (g in groupings) {

  ft_results <- sol_stats_data %>%
    filter(grouping == g) %>%
    select(!grouping) %>%
    column_to_rownames(var = "eval_label") %>%
    pairwise_fisher_test(
      p.adjust.method = "holm"
    ) %>%
    add_significance("p.adj")

  ft_results <- ft_results %>%
    mutate(
      comparison = rep(g, nrow(ft_results)),
      .keep = "all"
    ) %>%
    relocate(comparison)

  fisher_results <- rbind(
    fisher_results,
    ft_results
  )
}
fisher_results <- as.tibble(fisher_results)
fisher_results <- fisher_results %>%
  mutate(
    comparison = as.factor(comparison),
    group1 = as.factor(group1),
    group2 = as.factor(group2),
  ) %>%
  group_by(
    comparison
  )

fisher_table <- kbl(fisher_results) %>% kable_styling()
save_kable(fisher_table, paste0(plot_directory, "stats_table.pdf"))
fisher_table
```

## Average number of unique candidates selected

```{r}

full_avgs <- ts_data %>%
  filter(eval_label == "full") %>%
  group_by(PROBLEM) %>%
  summarize(
    n = n(),
    median_num_unique_selected = median(num_unique_selected),
    median_entropy_selected_ids = median(entropy_selected_ids),
    avg_num_unique_selected = mean(num_unique_selected),
    avg_entropy_selected_ids = mean(entropy_selected_ids)
  )


build_plot_summary_data <- function(
  data,
  response
) {
  plot <- data %>%
    filter(
      eval_label != "full"
    ) %>%
    ggplot(
      aes_string(
        x = "eval_label",
        y = response,
        fill = "eval_label"
      )
    ) +
    geom_flat_violin(
      position = position_nudge(x = .2, y = 0),
      alpha = .8,
      adjust = 1.5
    ) +
    geom_point(
      mapping = aes(color = eval_label),
      position = position_jitter(width = .15),
      size = .5,
      alpha = 0.8
    ) +
    geom_boxplot(
      width = .1,
      outlier.shape = NA,
      alpha = 0.5
    ) +
    scale_y_continuous(
      # limits = c(-0.5, 100)
    ) +
    scale_fill_bright() +
    scale_color_bright() +
    facet_grid(
      PROBLEM ~ evals_per_gen,
      # nrow=2,
      labeller = label_both
    ) +
    theme(
      legend.position = "none",
      axis.text.x = element_text(
        angle = 30,
        hjust = 1
      ),
      panel.border = element_rect(color = "gray", size = 2)
    )

  return(plot)
}

plt <- build_plot_summary_data(
  ts_avgs,
  "avg_num_unique_selected"
)
ggsave(
  filename = paste0(plot_directory, "avg_num_unique_selected.pdf"),
  plot = plt
)


plt <- build_plot_summary_data(
  ts_avgs,
  "avg_entropy_selected_ids"
)
ggsave(
  filename = paste0(plot_directory, "avg_entropy_selected_ids.pdf"),
  plot = plt
)

```

## Phylogeny-informed Trait Estimation Distance

How is trait estimation distance distributed across sampling conditions and GP problems?

Source materials for this analysis are available [here](https://osf.io/7mg3q).


> ![Histograms showing frequency of lookback distances for phylogeny-informed estimation.](https://raw.githubusercontent.com/amlalejini/GECCO-2024-phylogeny-informed-subsampling/f9f16c497747921992fb054cdfaaaa0073832840/experiments/2023-12-30-psynth/analysis/teeplots/col%3Deval-mode%2Belement%3Dpoly%2Bhue%3Dtest-downsample-rate%2Bstat%3Ddensity%2Bviz%3Dfacethist%2Bx%3Dtraining-cases-estimation-dist%2Bext%3D.png){height=200px}
> **Distribution of Estimation Distance and Downsample Rate.**
> As would be expected, more severe downsample rates thickened the tail of longer-distance trait estmations.
> However, under both downsampling rates, estimations at the maximimum allowed distance of 8 generations back were rare.
> Note that this visualization is a histogram and does not include confidence intervals.

> ![Histograms showing frequency of lookback distances for phylogeny-informed estimation.](https://raw.githubusercontent.com/amlalejini/GECCO-2024-phylogeny-informed-subsampling/f9f16c497747921992fb054cdfaaaa0073832840/experiments/2023-12-30-psynth/analysis/teeplots/col%3Deval-mode%2Belement%3Dpoly%2Bhue%3Dproblem%2Brow%3Dtest-downsample-rate%2Bstat%3Ddensity%2Bviz%3Dfacethist%2Bx%3Dtraining-cases-estimation-dist%2Bext%3D.png){height=400px}
> **Distribution of Estimation Distance by Program Synthesis Problem.**
> Estimation distance distributions appear similar between problems.

## Phylogeny-informed Trait Estimation Outcomes

What fraction of estimations are correct, incorrect, and failed?
First visualization includes trivial (distance 0) estimations and second visualization excludes them.

> ![Stackplots of trait estimation outcomes.](https://raw.githubusercontent.com/amlalejini/GECCO-2024-phylogeny-informed-subsampling/f9f16c497747921992fb054cdfaaaa0073832840/experiments/2023-12-30-psynth/analysis/teeplots/a%3Dwithtrivial-inclfail%2Bcol%3Deval-mode%2Bhue%3Dtrait-error-type%2Bmultiple%3Dfill%2Brow%3Dtest-downsample-rate%2Bstat%3Dproportion%2Bviz%3Dfacethist%2Bx%3Dproblem%2Bext%3D.png){height=400px}
> **Estimation Outcomes, Including Trival Estimations.**
As expected, correct estimations occur less frequenetly at the severe 1% downsample rate.
Except for the bouncing balls problem, more than half of estimations are correct at all downsample rates.
Estimation accuracy appears to be overall roughly comparable across all downsampling methods.

> ![Stackplots of trait estimation outcomes.](https://raw.githubusercontent.com/amlalejini/GECCO-2024-phylogeny-informed-subsampling/f9f16c497747921992fb054cdfaaaa0073832840/experiments/2023-12-30-psynth/analysis/teeplots/a%3Dnontrivial-inclfail%2Bcol%3Deval-mode%2Bhue%3Dtrait-error-type%2Bmultiple%3Dfill%2Brow%3Dtest-downsample-rate%2Bstat%3Dproportion%2Bviz%3Dfacethist%2Bx%3Dproblem%2Bext%3D.png){height=400px}
> **Estimation Outcomes, Excluding Trival Estimations.**
> As expected, higher fractions of incorrect estimations are observed when including only nontrivial estimations.
> (Distance zero estimations are equivalent to the true trait value unless execution is nondeterministic.)
>
> This effect is especially apparent for the bouncing balls and gcd problems under naive downsampling.
> At the 1% downsample rate, fewer than 25% of estimations are correct for these problems.
> However, as shown below, these problems are both continuous (rather than binary) with much estimation error being of small magnitude.

> ![Lineplot of estimatior rates by estimation distances.](https://raw.githubusercontent.com/amlalejini/GECCO-2024-phylogeny-informed-subsampling/f9f16c497747921992fb054cdfaaaa0073832840/experiments/2023-12-30-psynth/analysis/teeplots/a%3Dpercent-correct%2Bcol%3Deval-mode%2Bhue%3Dproblem%2Brow%3Dtest-downsample-rate%2Bviz%3Dfacetline%2Bx%3Dtraining-cases-estimation-dist%2By%3Dtrait-estimation-error%2Bext%3D.png){height=400px}
> **Percent Estimates Correct versus Lookup Distance.**
> For all surveyed conditions, estimation accuracy decreases when moving from trivial distance zero estimation to nontrivial distance one estimation.
> However, in many (but not all) conditions the fraction of correct estimations appears to plateau past lookup distance 2.
> The bouncing balls and gcd problems have the highest estimation errors at long estimation distance.
> Interestingly, estimation error appears to spike earlier for these problems under 1% downsampling than under 10% downsampling --- particularly, under naive downsampling.
> Other problems appear to show similar relationships between estimation error and lookup distance for both downsampling rates.
>
> Shaded intervals are bootstrapped 95% confidence intervals.
> This visualization excludes failed estimations.

## Distribution of Trait Estimation Error Magnidue

When trait estimation error occurs, how large is it?
Note that some problems have binary traits, so the magnitude of error is limited to 0 or 1.
Here, estimation error is calculated as a fraction of the true trait value.

> ![Strip plot of estimation error magnitudes.](https://raw.githubusercontent.com/amlalejini/GECCO-2024-phylogeny-informed-subsampling/f9f16c497747921992fb054cdfaaaa0073832840/experiments/2023-12-30-psynth/analysis/teeplots/a%3Derror-magnitude%2Bhue%3Dproblem%2Bviz%3Dvsplot%2Bx%3Dproblem%2By%3Dtrait-estimation-error%2Bext%3D.png){height=400px}
> **Distribution of Estimation Error.**
> Estimation error is generally unimodal, with bouncing balls having the tightest clustering of error near 0.0.
> For discrete traits, all estimation error is either -1 or 1.
> Note that this visualization excludes correct estimations (error magnitude exactly 0.0) and failed estimations.

> ![Lineplot of estimation error rates.](https://raw.githubusercontent.com/amlalejini/GECCO-2024-phylogeny-informed-subsampling/f9f16c497747921992fb054cdfaaaa0073832840/experiments/2023-12-30-psynth/analysis/teeplots/a%3Derror-magnitude%2Bcol%3Deval-mode%2Bhue%3Dproblem%2Brow%3Dtest-downsample-rate%2Bviz%3Dfacetline%2Bx%3Dtraining-cases-estimation-dist%2By%3Dtrait-estimation-error%2Bext%3D.png){height=400px}
> **Trait Estimation Error versus Lookup Distance.**
> When estimation error occurs, its magnitude is not obviously related to trait estimation distance.
> Note that binary traits estimation errors are all of magnitude 1.0.
>
> Shaded intervals are bootstrapped 95% confidence intervals.
> This visualization excludes failed estimations.
