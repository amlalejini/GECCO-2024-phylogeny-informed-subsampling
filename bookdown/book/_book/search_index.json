[["index.html", "Supplemental Material for ‘Runtime phylogenetic analysis enables extreme subsampling for test-based problems’ Chapter 1 Introduction 1.1 About our supplemental material 1.2 Contributing authors", " Supplemental Material for ‘Runtime phylogenetic analysis enables extreme subsampling for test-based problems’ Alexander Lalejini, Marcos Sanson, Jack Garbus, Matthew Andres Moreno, and Emily Dolson 2024-01-27 Chapter 1 Introduction This is not intended as a stand-alone document, but as a companion to our manuscript. 1.1 About our supplemental material As you may have noticed (unless you’re reading a pdf version of this), our supplemental material is hosted using GitHub pages. We compiled our data analyses and supplemental documentation into this nifty web-accessible book using bookdown. The source code/configuration files for this supplemental material can be found in this GitHub repository. Our supplemental material includes the following: Data availability (Section 2) Local compilation (Section 4) GP instruction set (Section 3) 1.2 Contributing authors Alexander Lalejini Marcos Sanson Jack Garbus Emily Dolson "],["data-availability.html", "Chapter 2 Data Availability 2.1 Source code 2.2 Training and testing sets 2.3 Experimental results", " Chapter 2 Data Availability 2.1 Source code The source code for this work is publicly accessible on GitHub: https://github.com/amlalejini/GECCO-2024-phylogeny-informed-subsampling. 2.1.1 Experiment software dependencies SignalGP: https://github.com/amlalejini/SignalGP commit hash: 114e0f07cb31370ab5191516679889e387cda73b Empirical: https://github.com/devosoft/Empirical commit hash: 5955a1cae2a5de36aa3a65df060a56b38f575bd0 psb-cpp: https://github.com/amlalejini/psb-cpp commit hash: e49896b957574ccd2f9e6e97e812971a0aa77f4b 2.2 Training and testing sets The training and testing sets used for program synthesis problems can be found on GitHub: https://github.com/amlalejini/GECCO-2024-phylogeny-informed-subsampling/tree/main/experiments/2023-12-30-psynth/hpc/config. 2.3 Experimental results All of our experimental data is available online from our OSF respository: https://osf.io/h3f52/ "],["signalgp-instruction-set.html", "Chapter 3 SignalGP instruction set 3.1 Default Instructions 3.2 Problem-specific instructions", " Chapter 3 SignalGP instruction set Below, we document the instruction set used in our GP system for our 2023 GPTP experiments. Abbreviations: EOP: End of program Reg: local register Reg[0] indicates the value at the register specified by an instruction’s first argument, Reg[1] indicates the value at the register specified by an instruction’s second argument, and Reg[2] indicates the value at the register specified by the instruction’s third argument. Reg[0], Reg[1], etc: Register 0, Register 1, etc. Input: input buffer Follows same scheme as Reg Output: output buffer Follows same scheme as Reg Global: global memory buffer Follows same scheme as Reg Arg: Instruction argument Arg[i] indicates the i’th instruction argument (an integer encoded in the genome) E.g., Arg[0] is an instruction’s first argument Instructions that would produce undefined behavior (e.g., division by zero) are treated as no operations. 3.1 Default Instructions I.e., instructions used across all diagnostic tasks. Instruction Arguments Used Description Nop 0 No operation Not 1 Reg[0] = !Reg[0] Inc 1 Reg[0] = Reg[0] + 1 Dec 1 Reg[0] = Reg[0] - 1 Add 3 Reg[2] = Reg[0] + Reg[1] Sub 3 Reg[2] = Reg[0] - Reg[1] Mult 3 Reg[2] = Reg[0] * Reg[1] Div 3 Reg[2] = Reg[0] / Reg[1] Mod 3 Reg[2] = Reg[0] % Reg[1] Nand 2 Reg[2] = !(Reg[0] &amp; Reg[1]) TestEqu 3 Reg[2] = Reg[0] == Reg[1] TestNEqu 3 Reg[2] = Reg[0] != Reg[1] TestLess 3 Reg[2] = Reg[0] &lt; Reg[1] TestLessEqu 3 Reg[2] = Reg[0] &lt;= Reg[1] TestGreater 3 Reg[2] = Reg[0] &gt; Reg[1] TestGreaterEqu 3 Reg[2] = Reg[0] &gt;= Reg[1] SetMem 2 Reg[0] = Arg[1] Terminal 1 Reg[0] = double value encoded by instruction tag CopyMem 2 Reg[0] = Reg[1] SwapMem 2 Swap(Reg[0], Reg[1]) InputToWorking 2 Reg[1] = Input[0] WorkingToOutput 2 Output[1] = Reg[0] If 1 If Reg[0] != 0, proceed. Otherwise skip to the next Close or EOP. While 1 While Reg[0] != 0, loop. Otherwise skip to next Close or EOP. Close 0 Indicate the end of a control block of code (e.g., loop, if). Break 0 Break out of current control flow (e.g., loop). Call 0 Call a function, using this instruction’s tag to determine which function is called. Routine 0 Same as call, but local memory is shared. Sort of like a jump that will jump back when the routine ends. Return 0 Return from the current function call. WorkingToGlobal 2 Global[1] = Reg[0] GlobalToWorking 2 Reg[1] = Global[0] FullGlobalToWorking 0 Copy entire global memory buffer into working memory buffer FullWorkingToGlobal 0 Copy entire working memory buffer into global memory buffer Note that Nand performs a bitwise operation. 3.2 Problem-specific instructions Each problem has problem-specific instructions for producing output. 3.2.1 Fizz Buzz SubmitFizz SubmitBuzz SubmitFizzBuzz SubmitEcho 3.2.2 Median SubmitOutput 3.2.3 Grade SubmitA SubmitB SubmitC SubmitD SubmitF 3.2.4 Small or large SubmitSmall SubmitLarge SubmitNeither "],["local-compilation.html", "Chapter 4 Local compilation", " Chapter 4 Local compilation You will need a C++ compiler that supports at least C++17. We used g++13 for all local compilations. First, clone GECCO-2024-phylogeny-informed-subsampling repository that contains the code needed to run our experiment software: https://github.com/amlalejini/GECCO-2024-phylogeny-informed-subsampling. Once cloned, cd into your local GECCO-2024-phylogeny-informed-subsampling repository directory. Then, initialize and update all of the git submodules: git submodule update --init --recursive Once the submodules are updated, you should be able to compile either the diagnostics or program synthesis experiment code. To specify which experiment you would like to compile, adjust the PROJECT variable in the Makefile. PROJECT := prog_synth for compiling the program synthesis code PROJECT := diagnostics for compiling the selection scheme diagnostics code To compile in debug mode, run make debug from repository directory, and to compile in release mode (all optimizations turned on), run make native. If you get the following error: third-party/Empirical/include/emp/matching/../../../third-party/robin-hood-hashing/src/include/robin_hood.h:54:14: fatal error: sys/auxv.h: No such file or directory 54 | # include &lt;sys/auxv.h&gt; // for getauxval you can fix it by doing the following: cd third-party/Empirical/third-party/robin-hood-hashing git checkout master Once you have an executable, you can generate a configuration file by running: ./prog_synth --gen prog_synth.cfg or ./diagnostics --gen diagnostics.cfg "],["exploitation-rate-diagnostic-experiments.html", "Chapter 5 Exploitation rate diagnostic experiments 5.1 Dependencies 5.2 Setup 5.3 Aggregate score 5.4 Number unique individual selected 5.5 Manuscript figures", " Chapter 5 Exploitation rate diagnostic experiments experiment_slug &lt;- &quot;2023-12-28-phylo-sampling-diag&quot; working_directory &lt;- paste0( &quot;experiments/&quot;, experiment_slug, &quot;/analysis/&quot; ) if (exists(&quot;bookdown_wd_prefix&quot;)) { working_directory &lt;- paste0( bookdown_wd_prefix, working_directory ) } 5.1 Dependencies library(tidyverse) ## ── Attaching core tidyverse packages ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 2.0.0 ── ## ✔ dplyr 1.1.4 ✔ readr 2.1.4 ## ✔ forcats 1.0.0 ✔ stringr 1.5.1 ## ✔ ggplot2 3.4.4 ✔ tibble 3.2.1 ## ✔ lubridate 1.9.3 ✔ tidyr 1.3.0 ## ✔ purrr 1.0.2 ## ── Conflicts ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors library(cowplot) ## ## Attaching package: &#39;cowplot&#39; ## ## The following object is masked from &#39;package:lubridate&#39;: ## ## stamp library(RColorBrewer) library(khroma) library(rstatix) ## ## Attaching package: &#39;rstatix&#39; ## ## The following object is masked from &#39;package:stats&#39;: ## ## filter library(knitr) source(&quot;https://gist.githubusercontent.com/benmarwick/2a1bb0133ff568cbe28d/raw/fb53bd97121f7f9ce947837ef1a4c65a73bffb3f/geom_flat_violin.R&quot;) print(version) ## _ ## platform aarch64-apple-darwin20 ## arch aarch64 ## os darwin20 ## system aarch64, darwin20 ## status ## major 4 ## minor 2.1 ## year 2022 ## month 06 ## day 23 ## svn rev 82513 ## language R ## version.string R version 4.2.1 (2022-06-23) ## nickname Funny-Looking Kid 5.2 Setup # Configure our default graphing theme theme_set(theme_cowplot()) # Create a directory to store plots plot_directory &lt;- paste0(working_directory, &quot;plots/&quot;) dir.create(plot_directory, showWarnings=FALSE) # Constants focal_diagnostic &lt;- &quot;exploitation-rate&quot; 5.2.1 Load experiment summary data summary_data_loc &lt;- paste0(working_directory, &quot;data/aggregate.csv&quot;) summary_data &lt;- read_csv(summary_data_loc) ## Rows: 1080 Columns: 58 ## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (5): DIAGNOSTIC, EVAL_FIT_EST_MODE, EVAL_MODE, SELECTION, STOP_MODE ## dbl (53): ACCURACY, CREDIT, DIAGNOSTIC_DIMENSIONALITY, EVAL_MAX_PHYLO_SEARCH... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. summary_data &lt;- summary_data %&gt;% mutate( evals_per_gen = case_when( EVAL_MODE == &quot;cohort-full-compete&quot; ~ 1.0 / NUM_COHORTS, EVAL_MODE == &quot;cohort&quot; ~ 1.0 / NUM_COHORTS, EVAL_MODE == &quot;down-sample&quot; ~ TEST_DOWNSAMPLE_RATE, EVAL_MODE == &quot;full&quot; ~ 1.0, EVAL_MODE == &quot;indiv-rand-sample&quot; ~ TEST_DOWNSAMPLE_RATE, EVAL_MODE == &quot;phylo-informed-sample&quot; ~ TEST_DOWNSAMPLE_RATE ), EVAL_FIT_EST_MODE = case_when( EVAL_FIT_EST_MODE == &quot;ancestor-opt&quot; ~ &quot;ancestor&quot;, EVAL_FIT_EST_MODE == &quot;relative-opt&quot; ~ &quot;relative&quot;, .default = EVAL_FIT_EST_MODE ), .keep = &quot;all&quot; ) %&gt;% mutate( eval_label = case_when( # Clean up down-sample label EVAL_MODE == &quot;down-sample&quot; &amp; EVAL_FIT_EST_MODE != &quot;none&quot; ~ paste(&quot;down-sample&quot;, EVAL_FIT_EST_MODE, sep=&quot;-&quot;), .default = EVAL_MODE ), ) %&gt;% mutate( evals_per_gen = as.factor(evals_per_gen), DIAGNOSTIC = as.factor(DIAGNOSTIC), SELECTION = as.factor(SELECTION), EVAL_MODE = as.factor(EVAL_MODE), NUM_COHORTS = as.factor(NUM_COHORTS), TEST_DOWNSAMPLE_RATE = as.factor(TEST_DOWNSAMPLE_RATE), EVAL_FIT_EST_MODE = factor( EVAL_FIT_EST_MODE, levels = c( &quot;none&quot;, &quot;ancestor&quot;, &quot;relative&quot; ), labels = c( &quot;None&quot;, &quot;Ancestor&quot;, &quot;Relative&quot; ) ) ) # Grab just the exploitation rate data exploit_summary_data &lt;- filter( summary_data, DIAGNOSTIC == &quot;exploitation-rate&quot; ) 5.2.2 Load experiment time series data ts_data_loc &lt;- paste0(working_directory, &quot;data/time_series.csv&quot;) ts_data &lt;- read_csv(ts_data_loc) ## Rows: 108000 Columns: 28 ## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (4): DIAGNOSTIC, EVAL_FIT_EST_MODE, EVAL_MODE, SELECTION ## dbl (24): NUM_COHORTS, SEED, TEST_DOWNSAMPLE_RATE, ave_depth, deleterious_st... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. ts_data &lt;- ts_data %&gt;% mutate( evals_per_gen = case_when( EVAL_MODE == &quot;cohort-full-compete&quot; ~ 1.0 / NUM_COHORTS, EVAL_MODE == &quot;cohort&quot; ~ 1.0 / NUM_COHORTS, EVAL_MODE == &quot;down-sample&quot; ~ TEST_DOWNSAMPLE_RATE, EVAL_MODE == &quot;full&quot; ~ 1.0, EVAL_MODE == &quot;indiv-rand-sample&quot; ~ TEST_DOWNSAMPLE_RATE, EVAL_MODE == &quot;phylo-informed-sample&quot; ~ TEST_DOWNSAMPLE_RATE ), EVAL_FIT_EST_MODE = case_when( EVAL_FIT_EST_MODE == &quot;ancestor-opt&quot; ~ &quot;ancestor&quot;, EVAL_FIT_EST_MODE == &quot;relative-opt&quot; ~ &quot;relative&quot;, .default = EVAL_FIT_EST_MODE ), .keep = &quot;all&quot; ) %&gt;% mutate( eval_label = case_when( EVAL_MODE == &quot;down-sample&quot; &amp; EVAL_FIT_EST_MODE != &quot;none&quot; ~ paste(&quot;down-sample&quot;, EVAL_FIT_EST_MODE, sep=&quot;-&quot;), .default = EVAL_MODE ) ) %&gt;% mutate( evals_per_gen = as.factor(evals_per_gen), DIAGNOSTIC = as.factor(DIAGNOSTIC), SELECTION = as.factor(SELECTION), EVAL_MODE = as.factor(EVAL_MODE), NUM_COHORTS = as.factor(NUM_COHORTS), TEST_DOWNSAMPLE_RATE = as.factor(TEST_DOWNSAMPLE_RATE), EVAL_FIT_EST_MODE = factor( EVAL_FIT_EST_MODE, levels = c( &quot;none&quot;, &quot;ancestor&quot;, &quot;relative&quot; ), labels = c( &quot;None&quot;, &quot;Ancestor&quot;, &quot;Relative&quot; ) ) ) # Grab just the exploitation rate data exploit_ts_data &lt;- ts_data %&gt;% filter(DIAGNOSTIC == &quot;exploitation-rate&quot;) Summarize time series data: ts_summary_data &lt;- ts_data %&gt;% group_by(SEED, DIAGNOSTIC, SELECTION, evals_per_gen, eval_label) %&gt;% summarize( n = n(), avg_num_unique_selected = mean(num_unique_selected), total_optimal_trait_coverage_loss = sum(optimal_trait_coverage_loss) ) ## `summarise()` has grouped output by &#39;SEED&#39;, &#39;DIAGNOSTIC&#39;, &#39;SELECTION&#39;, ## &#39;evals_per_gen&#39;. You can override using the `.groups` argument. 5.2.3 Plotting helper functions The following function assist with exploratory plotting of different measurements from summary and time series data. Note that for these plots, standard lexicase reference is rendered at equivalent number of generations (instead of evaluations). build_plot_summary_data &lt;- function(data, diagnostic, selection, response) { diag_data &lt;- data %&gt;% filter(DIAGNOSTIC == diagnostic) full_median &lt;- median( filter( diag_data, eval_label == &quot;full&quot; &amp; SELECTION == selection )[[response]] ) plot &lt;- diag_data %&gt;% filter( eval_label != &quot;full&quot; &amp; SELECTION == selection ) %&gt;% ggplot( aes_string( x = &quot;eval_label&quot;, y = response, fill = &quot;eval_label&quot; ) ) + geom_hline( yintercept = full_median, size = 1.0, alpha = 0.7, color = &quot;black&quot;, linetype=&quot;dashed&quot; ) + geom_flat_violin( position = position_nudge(x = .2, y = 0), alpha = .8, adjust = 1.5 ) + geom_point( mapping = aes(color = eval_label), position = position_jitter(width = .15), size = .5, alpha = 0.8 ) + geom_boxplot( width = .1, outlier.shape = NA, alpha = 0.5 ) + scale_y_continuous( # limits = c(-0.5, 100) ) + scale_fill_bright() + scale_color_bright() + facet_grid( SELECTION ~ evals_per_gen, # nrow=2, labeller = label_both ) + theme( legend.position = &quot;none&quot;, axis.text.x = element_text( angle = 30, hjust = 1 ), panel.border = element_rect(color = &quot;gray&quot;, size = 2) ) return(plot) } build_plot_time_series_single_sampling &lt;- function( data, diagnostic, selection, sampling_level, response ) { diag_data &lt;- data %&gt;% filter( DIAGNOSTIC == diagnostic &amp; SELECTION == selection &amp; evals_per_gen == sampling_level ) %&gt;% mutate( sampling_level_label = sampling_level ) full_diag_data &lt;- data %&gt;% filter( DIAGNOSTIC == diagnostic &amp; SELECTION == selection &amp; eval_label == &quot;full&quot; ) %&gt;% mutate( # Ensure that median line will sit in same facet sampling_level_label = sampling_level ) plot &lt;- diag_data %&gt;% filter( eval_label != &quot;full&quot; ) %&gt;% ggplot( aes_string( x = &quot;ts_step&quot;, # x = &quot;evaluations&quot;, y = {{ response }} ) ) + stat_summary( geom = &quot;line&quot;, fun = mean, aes( color = eval_label ) ) + stat_summary( geom = &quot;ribbon&quot;, fun.data = &quot;mean_cl_boot&quot;, fun.args = list(conf.int = 0.95), alpha = 0.2, linetype = 0, aes( color = eval_label, fill = eval_label ) ) + scale_fill_bright() + scale_color_bright() + # facet_wrap( # ~ sampling_level_label, # ncol = 1, # labeller = label_both # ) + theme( legend.position = &quot;right&quot; ) + stat_summary( data = full_diag_data, geom = &quot;line&quot;, fun = median, linetype = &quot;dashed&quot;, color = &quot;black&quot; ) return(plot) } build_plot_time_series &lt;- function( data, diagnostic, selection, response ) { # Build 1% sampling plot and 10% sampling plot p_01 &lt;- data %&gt;% build_plot_time_series_single_sampling( diagnostic, selection, &quot;0.01&quot;, response ) p_10 &lt;- data %&gt;% build_plot_time_series_single_sampling( diagnostic, selection, &quot;0.1&quot;, response ) title &lt;- ggdraw() + draw_label( paste0(diagnostic, &quot; - &quot;, selection), fontface = &#39;bold&#39;, x = 0, hjust = 0 ) + theme( # add margin on the left of the drawing canvas, # so title is aligned with left edge of first plot plot.margin = margin(0, 0, 0, 7) ) plot &lt;- plot_grid( title, p_01 + labs(title = &quot;1% subsampling&quot;) + theme(legend.position = &quot;none&quot;), p_10 + labs(title = &quot;10% subsampling&quot;) + theme(legend.position = &quot;bottom&quot;), nrow = 3, ncol = 1, rel_heights = c(0.075, 1, 1) ) return(plot) } 5.3 Aggregate score 5.3.1 Final - Lexicase selection p &lt;- summary_data %&gt;% build_plot_summary_data( &quot;exploitation-rate&quot;, &quot;lexicase&quot;, &quot;elite_true_agg_score&quot; ) ## Warning: `aes_string()` was deprecated in ggplot2 3.0.0. ## ℹ Please use tidy evaluation idioms with `aes()`. ## ℹ See also `vignette(&quot;ggplot2-in-packages&quot;)` for more information. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. ## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. ## ℹ Please use `linewidth` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. ## Warning: The `size` argument of `element_rect()` is deprecated as of ggplot2 3.4.0. ## ℹ Please use the `linewidth` argument instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. ggsave( filename = paste0(plot_directory, &quot;exploit-score-final-lex.pdf&quot;), plot = p + labs(title = &quot;Exploitation rate - Lexicase selection&quot;), width = 15, height = 10 ) ## Warning: Using the `size` aesthetic with geom_polygon was deprecated in ggplot2 3.4.0. ## ℹ Please use the `linewidth` aesthetic instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. 5.3.2 Final - Tournament selection p &lt;- summary_data %&gt;% build_plot_summary_data( &quot;exploitation-rate&quot;, &quot;tournament&quot;, &quot;elite_true_agg_score&quot; ) ggsave( filename = paste0(plot_directory, &quot;exploit-score-final-tourn.pdf&quot;), plot = p + labs(title = &quot;Exploitation rate - Tournament selection&quot;), width = 15, height = 10 ) 5.3.3 Statistical analysis First, we’ll create a table of median / mean values for easy reference. exploit_summary_data %&gt;% group_by(DIAGNOSTIC, SELECTION, evals_per_gen, eval_label) %&gt;% summarize( score_median = median(elite_true_agg_score), score_mean = mean(elite_true_agg_score), replicates = n() ) %&gt;% kable() ## `summarise()` has grouped output by &#39;DIAGNOSTIC&#39;, &#39;SELECTION&#39;, &#39;evals_per_gen&#39;. ## You can override using the `.groups` argument. DIAGNOSTIC SELECTION evals_per_gen eval_label score_median score_mean replicates exploitation-rate lexicase 0.01 down-sample 9933.1800 9933.2455 20 exploitation-rate lexicase 0.01 down-sample-ancestor 920.1625 913.6102 20 exploitation-rate lexicase 0.01 indiv-rand-sample 2117.1200 2137.2725 20 exploitation-rate lexicase 0.01 phylo-informed-sample 2157.9350 2162.8605 20 exploitation-rate lexicase 0.1 down-sample 9967.3500 9968.1275 20 exploitation-rate lexicase 0.1 down-sample-ancestor 6976.3600 6985.9325 20 exploitation-rate lexicase 0.1 indiv-rand-sample 9360.5800 9360.2230 20 exploitation-rate lexicase 0.1 phylo-informed-sample 9301.3500 9308.4105 20 exploitation-rate lexicase 1 full 9981.7200 9982.2910 20 exploitation-rate tournament 0.01 down-sample 9650.1650 9650.6660 20 exploitation-rate tournament 0.01 down-sample-ancestor 1023.4150 1011.8228 20 exploitation-rate tournament 0.01 indiv-rand-sample 9969.7650 9969.2945 20 exploitation-rate tournament 0.01 phylo-informed-sample 9970.8950 9970.1455 20 exploitation-rate tournament 0.1 down-sample 9972.3050 9972.0210 20 exploitation-rate tournament 0.1 down-sample-ancestor 9988.9200 9988.9365 20 exploitation-rate tournament 0.1 indiv-rand-sample 9999.8250 9999.8240 20 exploitation-rate tournament 0.1 phylo-informed-sample 9999.7700 9999.7800 20 exploitation-rate tournament 1 full 10000.0000 10000.0000 20 Next, we run a Kruskal-Wallis test to check for differences. For these tests, we only compare within a single subsampling level (evals_per_gen) and within the same selection scheme. kw_test &lt;- exploit_summary_data %&gt;% filter(eval_label != &quot;full&quot;) %&gt;% group_by(SELECTION, evals_per_gen) %&gt;% kruskal_test(elite_true_agg_score ~ eval_label) %&gt;% mutate(sig = (p &lt; 0.05)) %&gt;% unite( &quot;comparison_group&quot;, SELECTION, evals_per_gen, sep = &quot;_&quot;, remove = FALSE ) kable(kw_test) comparison_group SELECTION evals_per_gen .y. n statistic df p method sig lexicase_0.01 lexicase 0.01 elite_true_agg_score 80 67.04167 3 0 Kruskal-Wallis TRUE lexicase_0.1 lexicase 0.1 elite_true_agg_score 80 68.10074 3 0 Kruskal-Wallis TRUE tournament_0.01 tournament 0.01 elite_true_agg_score 80 66.76541 3 0 Kruskal-Wallis TRUE tournament_0.1 tournament 0.1 elite_true_agg_score 80 67.17274 3 0 Kruskal-Wallis TRUE Perform pairwise wilcoxon rank-sum tests for all significant comparison groups. # Grab group names of significant comparisons sig_kw_groups &lt;- filter(kw_test, p &lt; 0.05)$comparison_group wrs_test &lt;- exploit_summary_data %&gt;% unite( &quot;comparison_group&quot;, SELECTION, evals_per_gen, sep = &quot;_&quot;, remove = FALSE ) %&gt;% filter( eval_label != &quot;full&quot; &amp; comparison_group %in% sig_kw_groups ) %&gt;% group_by(SELECTION, evals_per_gen) %&gt;% pairwise_wilcox_test(elite_true_agg_score ~ eval_label) %&gt;% adjust_pvalue(method = &quot;holm&quot;) %&gt;% add_significance(&quot;p.adj&quot;) kable(wrs_test) SELECTION evals_per_gen .y. group1 group2 n1 n2 statistic p p.adj p.adj.signif lexicase 0.01 elite_true_agg_score down-sample down-sample-ancestor 20 20 400 0.00e+00 0.00e+00 **** lexicase 0.01 elite_true_agg_score down-sample indiv-rand-sample 20 20 400 0.00e+00 0.00e+00 **** lexicase 0.01 elite_true_agg_score down-sample phylo-informed-sample 20 20 400 0.00e+00 0.00e+00 **** lexicase 0.01 elite_true_agg_score down-sample-ancestor indiv-rand-sample 20 20 0 0.00e+00 0.00e+00 **** lexicase 0.01 elite_true_agg_score down-sample-ancestor phylo-informed-sample 20 20 0 0.00e+00 0.00e+00 **** lexicase 0.01 elite_true_agg_score indiv-rand-sample phylo-informed-sample 20 20 155 2.31e-01 5.13e-01 ns lexicase 0.1 elite_true_agg_score down-sample down-sample-ancestor 20 20 400 0.00e+00 0.00e+00 **** lexicase 0.1 elite_true_agg_score down-sample indiv-rand-sample 20 20 400 0.00e+00 0.00e+00 **** lexicase 0.1 elite_true_agg_score down-sample phylo-informed-sample 20 20 400 0.00e+00 0.00e+00 **** lexicase 0.1 elite_true_agg_score down-sample-ancestor indiv-rand-sample 20 20 0 0.00e+00 0.00e+00 **** lexicase 0.1 elite_true_agg_score down-sample-ancestor phylo-informed-sample 20 20 0 0.00e+00 0.00e+00 **** lexicase 0.1 elite_true_agg_score indiv-rand-sample phylo-informed-sample 20 20 288 1.70e-02 6.80e-02 ns tournament 0.01 elite_true_agg_score down-sample down-sample-ancestor 20 20 400 1.00e-07 7.00e-07 **** tournament 0.01 elite_true_agg_score down-sample indiv-rand-sample 20 20 0 0.00e+00 0.00e+00 **** tournament 0.01 elite_true_agg_score down-sample phylo-informed-sample 20 20 0 0.00e+00 0.00e+00 **** tournament 0.01 elite_true_agg_score down-sample-ancestor indiv-rand-sample 20 20 0 1.00e-07 7.00e-07 **** tournament 0.01 elite_true_agg_score down-sample-ancestor phylo-informed-sample 20 20 0 1.00e-07 7.00e-07 **** tournament 0.01 elite_true_agg_score indiv-rand-sample phylo-informed-sample 20 20 177 5.47e-01 5.47e-01 ns tournament 0.1 elite_true_agg_score down-sample down-sample-ancestor 20 20 0 0.00e+00 0.00e+00 **** tournament 0.1 elite_true_agg_score down-sample indiv-rand-sample 20 20 0 1.00e-07 7.00e-07 **** tournament 0.1 elite_true_agg_score down-sample phylo-informed-sample 20 20 0 1.00e-07 7.00e-07 **** tournament 0.1 elite_true_agg_score down-sample-ancestor indiv-rand-sample 20 20 0 1.00e-07 7.00e-07 **** tournament 0.1 elite_true_agg_score down-sample-ancestor phylo-informed-sample 20 20 0 1.00e-07 7.00e-07 **** tournament 0.1 elite_true_agg_score indiv-rand-sample phylo-informed-sample 20 20 251 1.71e-01 5.13e-01 ns 5.3.4 Over time - Lexicase p &lt;- ts_data %&gt;% build_plot_time_series( &quot;exploitation-rate&quot;, &quot;lexicase&quot;, &quot;max_agg_score&quot; ) ggsave( filename = paste0(plot_directory, &quot;exploit-score-ts-lex.pdf&quot;), plot = p, width = 15, height = 10 ) 5.3.5 Over time - Tournament p &lt;- ts_data %&gt;% build_plot_time_series( &quot;exploitation-rate&quot;, &quot;tournament&quot;, &quot;max_agg_score&quot; ) ggsave( filename = paste0(plot_directory, &quot;exploit-score-ts-tourn.pdf&quot;), plot = p, width = 15, height = 10 ) 5.4 Number unique individual selected build_plot_summary_data( ts_summary_data, focal_diagnostic, &quot;lexicase&quot;, &quot;avg_num_unique_selected&quot; ) Average number selected by standard lexicase? mean(filter( ts_summary_data, SELECTION == &quot;lexicase&quot; &amp; DIAGNOSTIC == &quot;exploitation-rate&quot; &amp; evals_per_gen == &quot;1&quot; )$avg_num_unique_selected) ## [1] 216.6185 mean(filter( ts_summary_data, SELECTION == &quot;lexicase&quot; &amp; DIAGNOSTIC == &quot;exploitation-rate&quot; &amp; evals_per_gen == &quot;0.1&quot;, eval_label == &quot;down-sample&quot; )$avg_num_unique_selected) ## [1] 28.099 mean(filter( ts_summary_data, SELECTION == &quot;lexicase&quot; &amp; DIAGNOSTIC == &quot;exploitation-rate&quot; &amp; evals_per_gen == &quot;0.01&quot;, eval_label == &quot;down-sample&quot; )$avg_num_unique_selected) ## [1] 120.7455 5.5 Manuscript figures Figures customized / cleaned up for the manuscript. build_final_score_manuscript_plot &lt;- function( selection, subsample_rate ) { # Extract median values for max aggregate score at same evaluation level # as sampling regimes max_eval &lt;- max( filter(exploit_ts_data, evals_per_gen == subsample_rate)$evaluations ) full_eval_steps &lt;- as.numeric( levels( as.factor( filter(exploit_ts_data, eval_label == &quot;full&quot; &amp; evaluations &gt;= max_eval)$evaluations # nolint: line_length_linter. ) ) ) full_eval &lt;- full_eval_steps[which.min( full_eval_steps - max_eval )] full_median_score_evals &lt;- median( filter( exploit_ts_data, SELECTION == selection &amp; eval_label == &quot;full&quot; &amp; evaluations == full_eval )$max_agg_score ) plot &lt;- exploit_summary_data %&gt;% filter( eval_label != &quot;full&quot; &amp; SELECTION == selection &amp; evals_per_gen == subsample_rate ) %&gt;% ggplot( aes( x = eval_label, y = elite_true_agg_score, fill = eval_label ) ) + geom_hline( yintercept = full_median_score_evals, size = 1.0, alpha = 0.7, color = &quot;black&quot;, linetype=&quot;dashed&quot; ) + geom_flat_violin( position = position_nudge(x = .2, y = 0), alpha = .8, adjust = 1.5 ) + geom_point( mapping = aes(color = eval_label), position = position_jitter(width = .15), size = .5, alpha = 0.8 ) + geom_boxplot( width = .1, outlier.shape = NA, alpha = 0.5 ) + scale_y_continuous( name = &quot;Aggregate score&quot;, limits = c(0, 10010) ) + scale_x_discrete( name = &quot;Subsampling regimes&quot;, breaks = c(&quot;down-sample&quot;, &quot;down-sample-ancestor&quot;, &quot;indiv-rand-sample&quot;, &quot;phylo-informed-sample&quot;), labels = c(&quot;DS&quot;, &quot;DS+EST&quot;, &quot;IRS&quot;, &quot;ABS&quot;) ) + scale_fill_bright() + scale_color_bright() + theme( legend.position = &quot;none&quot;, # axis.text.x = element_text( # angle = 30, # hjust = 1 # ), ) return(plot) } Build time series manuscript plot: build_score_over_time_manuscript_plot &lt;- function( selection, subsample_rate ) { max_eval &lt;- max( filter(exploit_ts_data, evals_per_gen == subsample_rate)$evaluations ) full_eval_steps &lt;- as.numeric( levels( as.factor( filter(exploit_ts_data, eval_label == &quot;full&quot; &amp; evaluations &gt;= max_eval)$evaluations # nolint: line_length_linter. ) ) ) full_eval &lt;- full_eval_steps[which.min( full_eval_steps - max_eval )] data &lt;- exploit_ts_data %&gt;% filter( SELECTION == selection &amp; evals_per_gen == subsample_rate ) %&gt;% mutate( sampling_level_label = subsample_rate ) full_diag_data &lt;- exploit_ts_data %&gt;% filter( SELECTION == selection &amp; eval_label == &quot;full&quot; &amp; evaluations &lt;= full_eval ) %&gt;% mutate( # Ensure that median line will sit in same facet sampling_level_label = subsample_rate ) plot &lt;- data %&gt;% filter( eval_label != &quot;full&quot; ) %&gt;% ggplot( aes( x = evaluations, y = max_agg_score ) ) + stat_summary( geom = &quot;line&quot;, fun = mean, aes( color = eval_label ) ) + stat_summary( geom = &quot;ribbon&quot;, fun.data = &quot;mean_cl_boot&quot;, fun.args = list(conf.int = 0.95), alpha = 0.2, linetype = 0, aes( color = eval_label, fill = eval_label ) ) + scale_y_continuous( name = &quot;Aggregate score&quot;, limits = c(0, 10010) ) + scale_x_continuous( name = &quot;Evaluations&quot; ) + scale_fill_bright( labels=c( &quot;Down-sampling (DS), no estimation&quot;, &quot;Down-sampling + Estimation (DS+EST)&quot;, &quot;Individualized random sampling (IRS)&quot;, &quot;Ancestor-based sampling (ABS)&quot; ) ) + scale_color_bright( labels=c( &quot;Down-sampling (DS), no estimation&quot;, &quot;Down-sampling + Estimation (DS+EST)&quot;, &quot;Individualized random sampling (IRS)&quot;, &quot;Ancestor-based sampling (ABS)&quot; ) ) + theme( legend.position = &quot;none&quot; ) + stat_summary( data = full_diag_data, geom = &quot;line&quot;, fun = median, linetype = &quot;dashed&quot;, color = &quot;black&quot; ) return(plot) } Build plots of final scores (after fixed number of evaluations) plot_final_lex_01 &lt;- build_final_score_manuscript_plot( &quot;lexicase&quot;, &quot;0.01&quot; ) plot_final_lex_10 &lt;- build_final_score_manuscript_plot( &quot;lexicase&quot;, &quot;0.1&quot; ) plot_final_tourn_01 &lt;- build_final_score_manuscript_plot( &quot;tournament&quot;, &quot;0.01&quot; ) plot_final_tourn_10 &lt;- build_final_score_manuscript_plot( &quot;tournament&quot;, &quot;0.1&quot; ) Build time series plots (with evaluations on x-axis) plot_ts_lex_01 &lt;- build_score_over_time_manuscript_plot( &quot;lexicase&quot;, &quot;0.01&quot; ) plot_ts_lex_10 &lt;- build_score_over_time_manuscript_plot( &quot;lexicase&quot;, &quot;0.1&quot; ) plot_ts_tourn_01 &lt;- build_score_over_time_manuscript_plot( &quot;tournament&quot;, &quot;0.01&quot; ) plot_ts_tourn_10 &lt;- build_score_over_time_manuscript_plot( &quot;tournament&quot;, &quot;0.1&quot; ) 5.5.1 Lexicase selection manuscript figure txt_size &lt;- 16 legend &lt;- get_legend( plot_ts_lex_01 + guides( color = guide_legend(nrow = 2, title = &quot;Subsampling regime:&quot;), fill = guide_legend(nrow = 2, title = &quot;Subsampling regime:&quot;) ) + theme( legend.position = &quot;bottom&quot;, legend.text = element_text(size = txt_size - 2), legend.title = element_text(size = txt_size) ) ) grid &lt;- plot_grid( plot_ts_lex_01 + labs(title = &quot;1% Subsampling&quot;) + theme( axis.text.x = element_text(size = txt_size-2), axis.text.y = element_text(size = txt_size), axis.title.x = element_text(size = txt_size), axis.title.y = element_text(size = txt_size) ), plot_final_lex_01 + theme( axis.text.y = element_blank(), axis.title.y = element_blank(), axis.ticks.y = element_blank(), plot.margin = margin(0, 0, 0, 1, &quot;cm&quot;), axis.text.x = element_text(size = txt_size), axis.title.x = element_text(size = txt_size) ), plot_ts_lex_10 + labs(title = &quot;10% Subsampling&quot;) + theme( axis.text.x = element_text(size = txt_size-2), axis.text.y = element_text(size = txt_size), axis.title.x = element_text(size = txt_size), axis.title.y = element_text(size = txt_size) ), plot_final_lex_10 + theme( axis.text.y = element_blank(), axis.title.y = element_blank(), axis.ticks.y = element_blank(), plot.margin = margin(0, 0, 0, 1, &quot;cm&quot;), axis.text.x = element_text(size = txt_size), axis.title.x = element_text(size = txt_size) ), nrow = 2, ncol = 2, align = &quot;h&quot;, labels = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;), label_size = 18, rel_widths = c(1.3, 1, 1.3, 1) ) grid lex_fig &lt;- plot_grid( grid, legend, nrow = 2, ncol = 1, rel_heights = c(1, 0.05) ) # lex_fig save_plot( filename = paste0(plot_directory, &quot;2023-12-28-exploit-lex-fig.pdf&quot;), plot = lex_fig, base_width = 10, base_height = 8, dpi = 600 ) 5.5.2 Tournament selection manuscript figures legend &lt;- get_legend( plot_ts_tourn_01 + guides( color = guide_legend(nrow = 2, title = &quot;Subsampling regime:&quot;), fill = guide_legend(nrow = 2, title = &quot;Subsampling regime:&quot;) ) + theme( legend.position = &quot;bottom&quot;, legend.text = element_text(size = txt_size - 2), legend.title = element_text(size = txt_size) ) ) grid &lt;- plot_grid( plot_ts_tourn_01 + labs(title = &quot;1% Subsampling&quot;) + theme( axis.text.x = element_text(size = txt_size-2), axis.text.y = element_text(size = txt_size), axis.title.x = element_text(size = txt_size), axis.title.y = element_text(size = txt_size) ), plot_final_tourn_01 + theme( axis.text.y = element_blank(), axis.title.y = element_blank(), axis.ticks.y = element_blank(), plot.margin = margin(0, 0, 0, 1, &quot;cm&quot;), axis.text.x = element_text(size = txt_size), axis.title.x = element_text(size = txt_size) ), plot_ts_tourn_10 + labs(title = &quot;10% Subsampling&quot;) + theme( axis.text.x = element_text(size = txt_size-2), axis.text.y = element_text(size = txt_size), axis.title.x = element_text(size = txt_size), axis.title.y = element_text(size = txt_size) ), plot_final_tourn_10 + theme( axis.text.y = element_blank(), axis.title.y = element_blank(), axis.ticks.y = element_blank(), plot.margin = margin(0, 0, 0, 1, &quot;cm&quot;), axis.text.x = element_text(size = txt_size), axis.title.x = element_text(size = txt_size) ), nrow = 2, ncol = 2, align = &quot;h&quot;, labels = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;), label_size = 18, rel_widths = c(1.3, 1, 1.3, 1) ) tourn_fig &lt;- plot_grid( grid, legend, nrow = 2, ncol = 1, rel_heights = c(1, 0.05) ) tourn_fig save_plot( filename = paste0(plot_directory, &quot;2023-12-28-exploit-tourn-fig.pdf&quot;), plot = tourn_fig, base_width = 10, base_height = 8, dpi = 600 ) "],["contradictory-objectives-diagnostic.html", "Chapter 6 Contradictory objectives diagnostic 6.1 Dependencies 6.2 Setup 6.3 Population-wide satisfactory trait coverage 6.4 MRCA changes 6.5 Mean genotype deleterious steps 6.6 Mean genotype pairwise distance 6.7 Number unique individual selected 6.8 Manuscript figures", " Chapter 6 Contradictory objectives diagnostic experiment_slug &lt;- &quot;2023-12-28-phylo-sampling-diag&quot; working_directory &lt;- paste0( &quot;experiments/&quot;, experiment_slug, &quot;/analysis/&quot; ) if (exists(&quot;bookdown_wd_prefix&quot;)) { working_directory &lt;- paste0( bookdown_wd_prefix, working_directory ) } 6.1 Dependencies library(tidyverse) library(cowplot) library(RColorBrewer) library(khroma) library(rstatix) library(knitr) source(&quot;https://gist.githubusercontent.com/benmarwick/2a1bb0133ff568cbe28d/raw/fb53bd97121f7f9ce947837ef1a4c65a73bffb3f/geom_flat_violin.R&quot;) print(version) ## _ ## platform aarch64-apple-darwin20 ## arch aarch64 ## os darwin20 ## system aarch64, darwin20 ## status ## major 4 ## minor 2.1 ## year 2022 ## month 06 ## day 23 ## svn rev 82513 ## language R ## version.string R version 4.2.1 (2022-06-23) ## nickname Funny-Looking Kid 6.2 Setup # Configure our default graphing theme theme_set(theme_cowplot()) # Create a directory to store plots plot_directory &lt;- paste0(working_directory, &quot;plots/&quot;) dir.create(plot_directory, showWarnings=FALSE) # Constants focal_diagnostic &lt;- &quot;contradictory-objectives&quot; 6.2.1 Load experiment summary data summary_data_loc &lt;- paste0(working_directory, &quot;data/aggregate.csv&quot;) summary_data &lt;- read_csv(summary_data_loc) ## Rows: 1080 Columns: 58 ## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (5): DIAGNOSTIC, EVAL_FIT_EST_MODE, EVAL_MODE, SELECTION, STOP_MODE ## dbl (53): ACCURACY, CREDIT, DIAGNOSTIC_DIMENSIONALITY, EVAL_MAX_PHYLO_SEARCH... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. summary_data &lt;- summary_data %&gt;% mutate( evals_per_gen = case_when( EVAL_MODE == &quot;cohort-full-compete&quot; ~ 1.0 / NUM_COHORTS, EVAL_MODE == &quot;cohort&quot; ~ 1.0 / NUM_COHORTS, EVAL_MODE == &quot;down-sample&quot; ~ TEST_DOWNSAMPLE_RATE, EVAL_MODE == &quot;full&quot; ~ 1.0, EVAL_MODE == &quot;indiv-rand-sample&quot; ~ TEST_DOWNSAMPLE_RATE, EVAL_MODE == &quot;phylo-informed-sample&quot; ~ TEST_DOWNSAMPLE_RATE ), EVAL_FIT_EST_MODE = case_when( EVAL_FIT_EST_MODE == &quot;ancestor-opt&quot; ~ &quot;ancestor&quot;, EVAL_FIT_EST_MODE == &quot;relative-opt&quot; ~ &quot;relative&quot;, .default = EVAL_FIT_EST_MODE ), .keep = &quot;all&quot; ) %&gt;% mutate( eval_label = case_when( # Clean up down-sample label EVAL_MODE == &quot;down-sample&quot; &amp; EVAL_FIT_EST_MODE != &quot;none&quot; ~ paste(&quot;down-sample&quot;, EVAL_FIT_EST_MODE, sep=&quot;-&quot;), .default = EVAL_MODE ), ) %&gt;% mutate( evals_per_gen = as.factor(evals_per_gen), DIAGNOSTIC = as.factor(DIAGNOSTIC), SELECTION = as.factor(SELECTION), EVAL_MODE = as.factor(EVAL_MODE), NUM_COHORTS = as.factor(NUM_COHORTS), TEST_DOWNSAMPLE_RATE = as.factor(TEST_DOWNSAMPLE_RATE), EVAL_FIT_EST_MODE = factor( EVAL_FIT_EST_MODE, levels = c( &quot;none&quot;, &quot;ancestor&quot;, &quot;relative&quot; ), labels = c( &quot;None&quot;, &quot;Ancestor&quot;, &quot;Relative&quot; ) ) ) # Grab just the contradictory objectives data con_obj_summary_data &lt;- filter( summary_data, DIAGNOSTIC == &quot;contradictory-objectives&quot; ) 6.2.2 Load experiment time series data ts_data_loc &lt;- paste0(working_directory, &quot;data/time_series.csv&quot;) ts_data &lt;- read_csv(ts_data_loc) ## Rows: 108000 Columns: 28 ## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (4): DIAGNOSTIC, EVAL_FIT_EST_MODE, EVAL_MODE, SELECTION ## dbl (24): NUM_COHORTS, SEED, TEST_DOWNSAMPLE_RATE, ave_depth, deleterious_st... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. ts_data &lt;- ts_data %&gt;% mutate( evals_per_gen = case_when( EVAL_MODE == &quot;cohort-full-compete&quot; ~ 1.0 / NUM_COHORTS, EVAL_MODE == &quot;cohort&quot; ~ 1.0 / NUM_COHORTS, EVAL_MODE == &quot;down-sample&quot; ~ TEST_DOWNSAMPLE_RATE, EVAL_MODE == &quot;full&quot; ~ 1.0, EVAL_MODE == &quot;indiv-rand-sample&quot; ~ TEST_DOWNSAMPLE_RATE, EVAL_MODE == &quot;phylo-informed-sample&quot; ~ TEST_DOWNSAMPLE_RATE ), EVAL_FIT_EST_MODE = case_when( EVAL_FIT_EST_MODE == &quot;ancestor-opt&quot; ~ &quot;ancestor&quot;, EVAL_FIT_EST_MODE == &quot;relative-opt&quot; ~ &quot;relative&quot;, .default = EVAL_FIT_EST_MODE ), .keep = &quot;all&quot; ) %&gt;% mutate( eval_label = case_when( EVAL_MODE == &quot;down-sample&quot; &amp; EVAL_FIT_EST_MODE != &quot;none&quot; ~ paste(&quot;down-sample&quot;, EVAL_FIT_EST_MODE, sep=&quot;-&quot;), .default = EVAL_MODE ) ) %&gt;% mutate( evals_per_gen = as.factor(evals_per_gen), DIAGNOSTIC = as.factor(DIAGNOSTIC), SELECTION = as.factor(SELECTION), EVAL_MODE = as.factor(EVAL_MODE), NUM_COHORTS = as.factor(NUM_COHORTS), TEST_DOWNSAMPLE_RATE = as.factor(TEST_DOWNSAMPLE_RATE), EVAL_FIT_EST_MODE = factor( EVAL_FIT_EST_MODE, levels = c( &quot;none&quot;, &quot;ancestor&quot;, &quot;relative&quot; ), labels = c( &quot;None&quot;, &quot;Ancestor&quot;, &quot;Relative&quot; ) ) ) # Grab just the contradictory objectives data con_obj_ts_data &lt;- ts_data %&gt;% filter(DIAGNOSTIC == &quot;contradictory-objectives&quot;) Summarize time series data: ts_summary_data &lt;- ts_data %&gt;% group_by(SEED, DIAGNOSTIC, SELECTION, evals_per_gen, eval_label) %&gt;% summarize( n = n(), avg_num_unique_selected = mean(num_unique_selected), total_optimal_trait_coverage_loss = sum(optimal_trait_coverage_loss) ) ## `summarise()` has grouped output by &#39;SEED&#39;, &#39;DIAGNOSTIC&#39;, &#39;SELECTION&#39;, ## &#39;evals_per_gen&#39;. You can override using the `.groups` argument. 6.2.3 Plotting helper functions The following function assist with exploratory plotting of different measurements from summary and time series data. Note that for these plots, standard lexicase reference is rendered at equivalent number of generations (instead of evaluations). build_plot_summary_data &lt;- function(data, diagnostic, selection, response) { diag_data &lt;- data %&gt;% filter(DIAGNOSTIC == diagnostic) full_median &lt;- median( filter( diag_data, eval_label == &quot;full&quot; &amp; SELECTION == selection )[[response]] ) plot &lt;- diag_data %&gt;% filter( eval_label != &quot;full&quot; &amp; SELECTION == selection ) %&gt;% ggplot( aes_string( x = &quot;eval_label&quot;, y = response, fill = &quot;eval_label&quot; ) ) + geom_hline( yintercept = full_median, size = 1.0, alpha = 0.7, color = &quot;black&quot;, linetype=&quot;dashed&quot; ) + geom_flat_violin( position = position_nudge(x = .2, y = 0), alpha = .8, adjust = 1.5 ) + geom_point( mapping = aes(color = eval_label), position = position_jitter(width = .15), size = .5, alpha = 0.8 ) + geom_boxplot( width = .1, outlier.shape = NA, alpha = 0.5 ) + scale_y_continuous( # limits = c(-0.5, 100) ) + scale_fill_bright() + scale_color_bright() + facet_grid( SELECTION ~ evals_per_gen, # nrow=2, labeller = label_both ) + theme( legend.position = &quot;none&quot;, axis.text.x = element_text( angle = 30, hjust = 1 ), panel.border = element_rect(color = &quot;gray&quot;, size = 2) ) return(plot) } build_plot_time_series_single_sampling &lt;- function( data, diagnostic, selection, sampling_level, response ) { diag_data &lt;- data %&gt;% filter( DIAGNOSTIC == diagnostic &amp; SELECTION == selection &amp; evals_per_gen == sampling_level ) %&gt;% mutate( sampling_level_label = sampling_level ) full_diag_data &lt;- data %&gt;% filter( DIAGNOSTIC == diagnostic &amp; SELECTION == selection &amp; eval_label == &quot;full&quot; ) %&gt;% mutate( # Ensure that median line will sit in same facet sampling_level_label = sampling_level ) plot &lt;- diag_data %&gt;% filter( eval_label != &quot;full&quot; ) %&gt;% ggplot( aes_string( x = &quot;ts_step&quot;, # x = &quot;evaluations&quot;, y = {{ response }} ) ) + stat_summary( geom = &quot;line&quot;, fun = mean, aes( color = eval_label ) ) + stat_summary( geom = &quot;ribbon&quot;, fun.data = &quot;mean_cl_boot&quot;, fun.args = list(conf.int = 0.95), alpha = 0.2, linetype = 0, aes( color = eval_label, fill = eval_label ) ) + scale_fill_bright() + scale_color_bright() + # facet_wrap( # ~ sampling_level_label, # ncol = 1, # labeller = label_both # ) + theme( legend.position = &quot;right&quot; ) + stat_summary( data = full_diag_data, geom = &quot;line&quot;, fun = median, linetype = &quot;dashed&quot;, color = &quot;black&quot; ) return(plot) } build_plot_time_series &lt;- function( data, diagnostic, selection, response ) { # Build 1% sampling plot and 10% sampling plot p_01 &lt;- data %&gt;% build_plot_time_series_single_sampling( diagnostic, selection, &quot;0.01&quot;, response ) p_10 &lt;- data %&gt;% build_plot_time_series_single_sampling( diagnostic, selection, &quot;0.1&quot;, response ) title &lt;- ggdraw() + draw_label( paste0(diagnostic, &quot; - &quot;, selection), fontface = &#39;bold&#39;, x = 0, hjust = 0 ) + theme( # add margin on the left of the drawing canvas, # so title is aligned with left edge of first plot plot.margin = margin(0, 0, 0, 7) ) plot &lt;- plot_grid( title, p_01 + labs(title = &quot;1% subsampling&quot;) + theme(legend.position = &quot;none&quot;), p_10 + labs(title = &quot;10% subsampling&quot;) + theme(legend.position = &quot;bottom&quot;), nrow = 3, ncol = 1, rel_heights = c(0.075, 1, 1) ) return(plot) } 6.3 Population-wide satisfactory trait coverage 6.3.1 Final - Lexicase selection p &lt;- summary_data %&gt;% build_plot_summary_data( focal_diagnostic, &quot;lexicase&quot;, &quot;pop_optimal_trait_coverage&quot; ) ggsave( filename = paste0(plot_directory, &quot;con-obj-sat-cov-final-lex.pdf&quot;), plot = p + labs(title = &quot;Contradictory objectives - Lexicase selection&quot;), width = 15, height = 10 ) 6.3.1.1 Statistics First, we’ll create a table of median / mean values for easy reference. con_obj_summary_data %&gt;% group_by(DIAGNOSTIC, SELECTION, evals_per_gen, eval_label) %&gt;% summarize( cov_median = median(pop_optimal_trait_coverage), cov_mean = mean(pop_optimal_trait_coverage), replicates = n() ) %&gt;% kable() ## `summarise()` has grouped output by &#39;DIAGNOSTIC&#39;, &#39;SELECTION&#39;, &#39;evals_per_gen&#39;. ## You can override using the `.groups` argument. DIAGNOSTIC SELECTION evals_per_gen eval_label cov_median cov_mean replicates contradictory-objectives lexicase 0.01 down-sample 1.0 1.00 20 contradictory-objectives lexicase 0.01 down-sample-ancestor 2.5 3.25 20 contradictory-objectives lexicase 0.01 indiv-rand-sample 8.0 8.20 20 contradictory-objectives lexicase 0.01 phylo-informed-sample 8.5 8.90 20 contradictory-objectives lexicase 0.1 down-sample 1.0 1.00 20 contradictory-objectives lexicase 0.1 down-sample-ancestor 17.5 18.15 20 contradictory-objectives lexicase 0.1 indiv-rand-sample 24.5 24.10 20 contradictory-objectives lexicase 0.1 phylo-informed-sample 24.0 24.25 20 contradictory-objectives lexicase 1 full 38.0 37.85 20 contradictory-objectives tournament 0.01 down-sample 1.0 1.00 20 contradictory-objectives tournament 0.01 down-sample-ancestor 1.0 1.00 20 contradictory-objectives tournament 0.01 indiv-rand-sample 1.0 1.00 20 contradictory-objectives tournament 0.01 phylo-informed-sample 1.0 1.00 20 contradictory-objectives tournament 0.1 down-sample 1.0 1.00 20 contradictory-objectives tournament 0.1 down-sample-ancestor 1.0 1.00 20 contradictory-objectives tournament 0.1 indiv-rand-sample 1.0 1.00 20 contradictory-objectives tournament 0.1 phylo-informed-sample 1.0 1.00 20 contradictory-objectives tournament 1 full 1.0 1.00 20 Next, we run a Kruskal-Wallis test to check for differences. For these tests, we only compare within a single subsampling level (evals_per_gen) and within the same selection scheme. kw_test &lt;- con_obj_summary_data %&gt;% filter(eval_label != &quot;full&quot;) %&gt;% group_by(SELECTION, evals_per_gen) %&gt;% kruskal_test(pop_optimal_trait_coverage ~ eval_label) %&gt;% mutate(sig = (p &lt; 0.05)) %&gt;% unite( &quot;comparison_group&quot;, SELECTION, evals_per_gen, sep = &quot;_&quot;, remove = FALSE ) kable(kw_test) comparison_group SELECTION evals_per_gen .y. n statistic df p method sig lexicase_0.01 lexicase 0.01 pop_optimal_trait_coverage 80 58.24682 3 0 Kruskal-Wallis TRUE lexicase_0.1 lexicase 0.1 pop_optimal_trait_coverage 80 62.11510 3 0 Kruskal-Wallis TRUE tournament_0.01 tournament 0.01 pop_optimal_trait_coverage 80 NaN 3 NaN Kruskal-Wallis NA tournament_0.1 tournament 0.1 pop_optimal_trait_coverage 80 NaN 3 NaN Kruskal-Wallis NA # Grab group names of significant comparisons sig_kw_groups &lt;- filter(kw_test, p &lt; 0.05)$comparison_group wrs_test &lt;- con_obj_summary_data %&gt;% unite( &quot;comparison_group&quot;, SELECTION, evals_per_gen, sep = &quot;_&quot;, remove = FALSE ) %&gt;% filter( eval_label != &quot;full&quot; &amp; comparison_group %in% sig_kw_groups ) %&gt;% group_by(SELECTION, evals_per_gen) %&gt;% pairwise_wilcox_test(pop_optimal_trait_coverage ~ eval_label) %&gt;% adjust_pvalue(method = &quot;holm&quot;) %&gt;% add_significance(&quot;p.adj&quot;) kable(wrs_test) SELECTION evals_per_gen .y. group1 group2 n1 n2 statistic p p.adj p.adj.signif lexicase 0.01 pop_optimal_trait_coverage down-sample down-sample-ancestor 20 20 50 3.20e-06 1.91e-05 **** lexicase 0.01 pop_optimal_trait_coverage down-sample indiv-rand-sample 20 20 0 0.00e+00 1.00e-07 **** lexicase 0.01 pop_optimal_trait_coverage down-sample phylo-informed-sample 20 20 0 0.00e+00 1.00e-07 **** lexicase 0.01 pop_optimal_trait_coverage down-sample-ancestor indiv-rand-sample 20 20 37 9.80e-06 2.93e-05 **** lexicase 0.01 pop_optimal_trait_coverage down-sample-ancestor phylo-informed-sample 20 20 28 3.20e-06 1.91e-05 **** lexicase 0.01 pop_optimal_trait_coverage indiv-rand-sample phylo-informed-sample 20 20 181 6.14e-01 1.00e+00 ns lexicase 0.1 pop_optimal_trait_coverage down-sample down-sample-ancestor 20 20 0 0.00e+00 1.00e-07 **** lexicase 0.1 pop_optimal_trait_coverage down-sample indiv-rand-sample 20 20 0 0.00e+00 1.00e-07 **** lexicase 0.1 pop_optimal_trait_coverage down-sample phylo-informed-sample 20 20 0 0.00e+00 1.00e-07 **** lexicase 0.1 pop_optimal_trait_coverage down-sample-ancestor indiv-rand-sample 20 20 31 4.90e-06 1.95e-05 **** lexicase 0.1 pop_optimal_trait_coverage down-sample-ancestor phylo-informed-sample 20 20 24 1.90e-06 1.32e-05 **** lexicase 0.1 pop_optimal_trait_coverage indiv-rand-sample phylo-informed-sample 20 20 203 9.46e-01 1.00e+00 ns 6.3.2 Over time - lexicase selection p &lt;- ts_data %&gt;% build_plot_time_series( focal_diagnostic, &quot;lexicase&quot;, &quot;pop_optimal_trait_coverage&quot; ) ggsave( filename = paste0(plot_directory, &quot;con-obj-sat-cov-ts-lex.pdf&quot;), plot = p, width = 15, height = 10 ) 6.3.3 Final - Tournament selection p &lt;- summary_data %&gt;% build_plot_summary_data( focal_diagnostic, &quot;tournament&quot;, &quot;pop_optimal_trait_coverage&quot; ) ggsave( filename = paste0(plot_directory, &quot;con-obj-sat-cov-final-tourn.pdf&quot;), plot = p + labs(title = &quot;Contradictory objectives - Tournament selection&quot;), width = 15, height = 10 ) 6.3.4 Over time - tournament selection p &lt;- ts_data %&gt;% build_plot_time_series( focal_diagnostic, &quot;tournament&quot;, &quot;pop_optimal_trait_coverage&quot; ) ggsave( filename = paste0(plot_directory, &quot;con-obj-sat-cov-ts-tourn.pdf&quot;), plot = p, width = 15, height = 10 ) 6.4 MRCA changes p &lt;- summary_data %&gt;% build_plot_summary_data( focal_diagnostic, &quot;lexicase&quot;, &quot;phylo_mrca_changes&quot; ) ggsave( filename = paste0(plot_directory, &quot;con-obj-mrca-chgs-final-lex.pdf&quot;), plot = p + labs(title = &quot;Contradictory objectives - Lexicase selection&quot;), width = 15, height = 10 ) 6.5 Mean genotype deleterious steps p &lt;- summary_data %&gt;% build_plot_summary_data( focal_diagnostic, &quot;lexicase&quot;, &quot;phylo_mean_genoetype_deleterious_steps&quot; ) ggsave( filename = paste0(plot_directory, &quot;con-obj-del-steps-final-lex.pdf&quot;), plot = p + labs(title = &quot;Contradictory objectives - Lexicase selection&quot;), width = 15, height = 10 ) 6.6 Mean genotype pairwise distance p &lt;- summary_data %&gt;% build_plot_summary_data( focal_diagnostic, &quot;lexicase&quot;, &quot;phylo_mean_genotype_pairwise_distance&quot; ) ggsave( filename = paste0(plot_directory, &quot;con-obj-pw-dist-final-lex.pdf&quot;), plot = p + labs(title = &quot;Contradictory objectives - Lexicase selection&quot;), width = 15, height = 10 ) 6.7 Number unique individual selected build_plot_summary_data( ts_summary_data, focal_diagnostic, &quot;lexicase&quot;, &quot;avg_num_unique_selected&quot; ) 6.8 Manuscript figures Time series graphs don’t add a ton here, so just final graphs. build_final_score_manuscript_plot &lt;- function( selection, subsample_rate ) { # Extract median values for max aggregate score at same evaluation level as sampling regimes max_eval &lt;- max( filter(con_obj_summary_data, evals_per_gen == subsample_rate)$evaluations ) full_eval_steps &lt;- as.numeric( levels( as.factor( filter(con_obj_summary_data, eval_label == &quot;full&quot; &amp; evaluations &gt;= max_eval)$evaluations # nolint: line_length_linter. ) ) ) full_eval &lt;- full_eval_steps[which.min( full_eval_steps - max_eval )] full_median_score_evals &lt;- median( filter( con_obj_summary_data, SELECTION == selection &amp; eval_label == &quot;full&quot; &amp; evaluations == full_eval )$pop_optimal_trait_coverage ) plot &lt;- con_obj_summary_data %&gt;% filter( eval_label != &quot;full&quot; &amp; SELECTION == selection &amp; evals_per_gen == subsample_rate ) %&gt;% ggplot( aes( x = eval_label, y = pop_optimal_trait_coverage, fill = eval_label ) ) + geom_hline( yintercept = full_median_score_evals, size = 1.0, alpha = 0.7, color = &quot;black&quot;, linetype=&quot;dashed&quot; ) + geom_flat_violin( position = position_nudge(x = .2, y = 0), alpha = .8, adjust = 1.5 ) + geom_point( mapping = aes(color = eval_label), position = position_jitter(width = .15), size = .5, alpha = 0.8 ) + geom_boxplot( width = .1, outlier.shape = NA, alpha = 0.5 ) + scale_y_continuous( name = &quot;Satisfactory trait coverage&quot;, limits = c(0, 100) ) + scale_x_discrete( name = &quot;Subsampling regime&quot;, breaks = c(&quot;down-sample&quot;, &quot;down-sample-ancestor&quot;, &quot;indiv-rand-sample&quot;, &quot;phylo-informed-sample&quot;), labels = c(&quot;DS\\n(no est.)&quot;, &quot;DS+EST&quot;, &quot;IRS&quot;, &quot;ABS&quot;) ) + scale_fill_bright() + scale_color_bright() + theme( legend.position = &quot;none&quot;, # axis.text.x = element_text( # angle = 30, # hjust = 1 # ), ) return(plot) } Build end-of-run plots (fixed number of evaluations) plot_final_lex_01 &lt;- build_final_score_manuscript_plot( &quot;lexicase&quot;, &quot;0.01&quot; ) plot_final_lex_10 &lt;- build_final_score_manuscript_plot( &quot;lexicase&quot;, &quot;0.1&quot; ) Combine into single figure lex_fig &lt;- plot_grid( plot_final_lex_01 + # labs( # title = &quot;1% subsampling&quot; # ) + theme( plot.margin = margin(1, 0, 0, 0, &quot;cm&quot;) ), plot_final_lex_10 + # labs( # title = &quot;10% subsampling&quot; # ) + theme( axis.text.y = element_blank(), axis.title.y = element_blank(), axis.ticks.y = element_blank(), plot.margin = margin(1, 0, 0, 1, &quot;cm&quot;) ), nrow = 1, ncol = 2, align = &quot;h&quot;, labels = c(&quot;a) 1% subsampling&quot;, &quot;b) 10% subsampling&quot;), rel_widths = c(1, 1) ) lex_fig save_plot( filename = paste0(plot_directory, &quot;2023-12-28-con-obj-lex-fig.pdf&quot;), plot = lex_fig, base_width = 7, base_height = 4, dpi = 600 ) "],["multi-path-exploration-diagnostic.html", "Chapter 7 Multi-path exploration diagnostic 7.1 Dependencies 7.2 Setup 7.3 Aggregate score 7.4 Manuscript figures", " Chapter 7 Multi-path exploration diagnostic experiment_slug &lt;- &quot;2023-12-28-phylo-sampling-diag&quot; working_directory &lt;- paste0( &quot;experiments/&quot;, experiment_slug, &quot;/analysis/&quot; ) if (exists(&quot;bookdown_wd_prefix&quot;)) { working_directory &lt;- paste0( bookdown_wd_prefix, working_directory ) } 7.1 Dependencies library(tidyverse) library(cowplot) library(RColorBrewer) library(khroma) library(rstatix) library(knitr) source(&quot;https://gist.githubusercontent.com/benmarwick/2a1bb0133ff568cbe28d/raw/fb53bd97121f7f9ce947837ef1a4c65a73bffb3f/geom_flat_violin.R&quot;) print(version) ## _ ## platform aarch64-apple-darwin20 ## arch aarch64 ## os darwin20 ## system aarch64, darwin20 ## status ## major 4 ## minor 2.1 ## year 2022 ## month 06 ## day 23 ## svn rev 82513 ## language R ## version.string R version 4.2.1 (2022-06-23) ## nickname Funny-Looking Kid 7.2 Setup # Configure our default graphing theme theme_set(theme_cowplot()) # Create a directory to store plots plot_directory &lt;- paste0(working_directory, &quot;plots/&quot;) dir.create(plot_directory, showWarnings=FALSE) # Constants focal_diagnostic &lt;- &quot;multipath-exploration&quot; 7.2.1 Load experiment summary data summary_data_loc &lt;- paste0(working_directory, &quot;data/aggregate.csv&quot;) summary_data &lt;- read_csv(summary_data_loc) ## Rows: 1080 Columns: 58 ## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (5): DIAGNOSTIC, EVAL_FIT_EST_MODE, EVAL_MODE, SELECTION, STOP_MODE ## dbl (53): ACCURACY, CREDIT, DIAGNOSTIC_DIMENSIONALITY, EVAL_MAX_PHYLO_SEARCH... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. summary_data &lt;- summary_data %&gt;% mutate( evals_per_gen = case_when( EVAL_MODE == &quot;cohort-full-compete&quot; ~ 1.0 / NUM_COHORTS, EVAL_MODE == &quot;cohort&quot; ~ 1.0 / NUM_COHORTS, EVAL_MODE == &quot;down-sample&quot; ~ TEST_DOWNSAMPLE_RATE, EVAL_MODE == &quot;full&quot; ~ 1.0, EVAL_MODE == &quot;indiv-rand-sample&quot; ~ TEST_DOWNSAMPLE_RATE, EVAL_MODE == &quot;phylo-informed-sample&quot; ~ TEST_DOWNSAMPLE_RATE ), EVAL_FIT_EST_MODE = case_when( EVAL_FIT_EST_MODE == &quot;ancestor-opt&quot; ~ &quot;ancestor&quot;, EVAL_FIT_EST_MODE == &quot;relative-opt&quot; ~ &quot;relative&quot;, .default = EVAL_FIT_EST_MODE ), .keep = &quot;all&quot; ) %&gt;% mutate( eval_label = case_when( # Clean up down-sample label EVAL_MODE == &quot;down-sample&quot; &amp; EVAL_FIT_EST_MODE != &quot;none&quot; ~ paste(&quot;down-sample&quot;, EVAL_FIT_EST_MODE, sep=&quot;-&quot;), .default = EVAL_MODE ), ) %&gt;% mutate( evals_per_gen = as.factor(evals_per_gen), DIAGNOSTIC = as.factor(DIAGNOSTIC), SELECTION = as.factor(SELECTION), EVAL_MODE = as.factor(EVAL_MODE), NUM_COHORTS = as.factor(NUM_COHORTS), TEST_DOWNSAMPLE_RATE = as.factor(TEST_DOWNSAMPLE_RATE), EVAL_FIT_EST_MODE = factor( EVAL_FIT_EST_MODE, levels = c( &quot;none&quot;, &quot;ancestor&quot;, &quot;relative&quot; ), labels = c( &quot;None&quot;, &quot;Ancestor&quot;, &quot;Relative&quot; ) ) ) explore_summary_data &lt;- filter( summary_data, DIAGNOSTIC == &quot;multipath-exploration&quot; ) 7.2.2 Load experiment time series data ts_data_loc &lt;- paste0(working_directory, &quot;data/time_series.csv&quot;) ts_data &lt;- read_csv(ts_data_loc) ## Rows: 108000 Columns: 28 ## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (4): DIAGNOSTIC, EVAL_FIT_EST_MODE, EVAL_MODE, SELECTION ## dbl (24): NUM_COHORTS, SEED, TEST_DOWNSAMPLE_RATE, ave_depth, deleterious_st... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. ts_data &lt;- ts_data %&gt;% mutate( evals_per_gen = case_when( EVAL_MODE == &quot;cohort-full-compete&quot; ~ 1.0 / NUM_COHORTS, EVAL_MODE == &quot;cohort&quot; ~ 1.0 / NUM_COHORTS, EVAL_MODE == &quot;down-sample&quot; ~ TEST_DOWNSAMPLE_RATE, EVAL_MODE == &quot;full&quot; ~ 1.0, EVAL_MODE == &quot;indiv-rand-sample&quot; ~ TEST_DOWNSAMPLE_RATE, EVAL_MODE == &quot;phylo-informed-sample&quot; ~ TEST_DOWNSAMPLE_RATE ), EVAL_FIT_EST_MODE = case_when( EVAL_FIT_EST_MODE == &quot;ancestor-opt&quot; ~ &quot;ancestor&quot;, EVAL_FIT_EST_MODE == &quot;relative-opt&quot; ~ &quot;relative&quot;, .default = EVAL_FIT_EST_MODE ), .keep = &quot;all&quot; ) %&gt;% mutate( eval_label = case_when( EVAL_MODE == &quot;down-sample&quot; &amp; EVAL_FIT_EST_MODE != &quot;none&quot; ~ paste(&quot;down-sample&quot;, EVAL_FIT_EST_MODE, sep=&quot;-&quot;), .default = EVAL_MODE ) ) %&gt;% mutate( evals_per_gen = as.factor(evals_per_gen), DIAGNOSTIC = as.factor(DIAGNOSTIC), SELECTION = as.factor(SELECTION), EVAL_MODE = as.factor(EVAL_MODE), NUM_COHORTS = as.factor(NUM_COHORTS), TEST_DOWNSAMPLE_RATE = as.factor(TEST_DOWNSAMPLE_RATE), EVAL_FIT_EST_MODE = factor( EVAL_FIT_EST_MODE, levels = c( &quot;none&quot;, &quot;ancestor&quot;, &quot;relative&quot; ), labels = c( &quot;None&quot;, &quot;Ancestor&quot;, &quot;Relative&quot; ) ) ) explore_ts_data &lt;- ts_data %&gt;% filter(DIAGNOSTIC == &quot;multipath-exploration&quot;) Summarize time series data ts_summary_data &lt;- ts_data %&gt;% group_by(SEED, DIAGNOSTIC, SELECTION, evals_per_gen, eval_label) %&gt;% summarize( n = n(), avg_num_unique_selected = mean(num_unique_selected), total_optimal_trait_coverage_loss = sum(optimal_trait_coverage_loss) ) ## `summarise()` has grouped output by &#39;SEED&#39;, &#39;DIAGNOSTIC&#39;, &#39;SELECTION&#39;, ## &#39;evals_per_gen&#39;. You can override using the `.groups` argument. 7.2.3 Plotting helper functions The following function assist with exploratory plotting of different measurements from summary and time series data. Note that for these plots, standard lexicase reference is rendered at equivalent number of generations (instead of evaluations). build_plot_summary_data &lt;- function(data, diagnostic, selection, response) { diag_data &lt;- data %&gt;% filter(DIAGNOSTIC == diagnostic) full_median &lt;- median( filter( diag_data, eval_label == &quot;full&quot; &amp; SELECTION == selection )[[response]] ) plot &lt;- diag_data %&gt;% filter( eval_label != &quot;full&quot; &amp; SELECTION == selection ) %&gt;% ggplot( aes_string( x = &quot;eval_label&quot;, y = response, fill = &quot;eval_label&quot; ) ) + geom_hline( yintercept = full_median, size = 1.0, alpha = 0.7, color = &quot;black&quot;, linetype=&quot;dashed&quot; ) + geom_flat_violin( position = position_nudge(x = .2, y = 0), alpha = .8, adjust = 1.5 ) + geom_point( mapping = aes(color = eval_label), position = position_jitter(width = .15), size = .5, alpha = 0.8 ) + geom_boxplot( width = .1, outlier.shape = NA, alpha = 0.5 ) + scale_y_continuous( # limits = c(-0.5, 100) ) + scale_fill_bright() + scale_color_bright() + facet_grid( SELECTION ~ evals_per_gen, # nrow=2, labeller = label_both ) + theme( legend.position = &quot;none&quot;, axis.text.x = element_text( angle = 30, hjust = 1 ), panel.border = element_rect(color = &quot;gray&quot;, size = 2) ) return(plot) } build_plot_time_series_single_sampling &lt;- function( data, diagnostic, selection, sampling_level, response ) { diag_data &lt;- data %&gt;% filter( DIAGNOSTIC == diagnostic &amp; SELECTION == selection &amp; evals_per_gen == sampling_level ) %&gt;% mutate( sampling_level_label = sampling_level ) full_diag_data &lt;- data %&gt;% filter( DIAGNOSTIC == diagnostic &amp; SELECTION == selection &amp; eval_label == &quot;full&quot; ) %&gt;% mutate( # Ensure that median line will sit in same facet sampling_level_label = sampling_level ) plot &lt;- diag_data %&gt;% filter( eval_label != &quot;full&quot; ) %&gt;% ggplot( aes_string( x = &quot;ts_step&quot;, # x = &quot;evaluations&quot;, y = {{ response }} ) ) + stat_summary( geom = &quot;line&quot;, fun = mean, aes( color = eval_label ) ) + stat_summary( geom = &quot;ribbon&quot;, fun.data = &quot;mean_cl_boot&quot;, fun.args = list(conf.int = 0.95), alpha = 0.2, linetype = 0, aes( color = eval_label, fill = eval_label ) ) + scale_fill_bright() + scale_color_bright() + # facet_wrap( # ~ sampling_level_label, # ncol = 1, # labeller = label_both # ) + theme( legend.position = &quot;right&quot; ) + stat_summary( data = full_diag_data, geom = &quot;line&quot;, fun = median, linetype = &quot;dashed&quot;, color = &quot;black&quot; ) return(plot) } build_plot_time_series &lt;- function( data, diagnostic, selection, response ) { # Build 1% sampling plot and 10% sampling plot p_01 &lt;- data %&gt;% build_plot_time_series_single_sampling( diagnostic, selection, &quot;0.01&quot;, response ) p_10 &lt;- data %&gt;% build_plot_time_series_single_sampling( diagnostic, selection, &quot;0.1&quot;, response ) title &lt;- ggdraw() + draw_label( paste0(diagnostic, &quot; - &quot;, selection), fontface = &#39;bold&#39;, x = 0, hjust = 0 ) + theme( # add margin on the left of the drawing canvas, # so title is aligned with left edge of first plot plot.margin = margin(0, 0, 0, 7) ) plot &lt;- plot_grid( title, p_01 + labs(title = &quot;1% subsampling&quot;) + theme(legend.position = &quot;none&quot;), p_10 + labs(title = &quot;10% subsampling&quot;) + theme(legend.position = &quot;bottom&quot;), nrow = 3, ncol = 1, rel_heights = c(0.075, 1, 1) ) return(plot) } 7.3 Aggregate score 7.3.1 Final - Lexicase selection Note that lexicase baseline is shown @ 50,000 generations (not same number of evaluations). p &lt;- summary_data %&gt;% build_plot_summary_data( &quot;multipath-exploration&quot;, &quot;lexicase&quot;, &quot;elite_true_agg_score&quot; ) ggsave( filename = paste0(plot_directory, &quot;explore-score-final-lex.pdf&quot;), plot = p + labs(title = &quot;Exploration rate - Lexicase selection&quot;), width = 15, height = 10 ) 7.3.1.1 Statistics First, we’ll create a table of median / mean values for easy reference. explore_summary_data %&gt;% group_by(DIAGNOSTIC, SELECTION, evals_per_gen, eval_label) %&gt;% summarize( score_median = median(elite_true_agg_score), score_mean = mean(elite_true_agg_score), replicates = n() ) %&gt;% kable() ## `summarise()` has grouped output by &#39;DIAGNOSTIC&#39;, &#39;SELECTION&#39;, &#39;evals_per_gen&#39;. ## You can override using the `.groups` argument. DIAGNOSTIC SELECTION evals_per_gen eval_label score_median score_mean replicates multipath-exploration lexicase 0.01 down-sample 481.7515 545.8618 20 multipath-exploration lexicase 0.01 down-sample-ancestor 343.1445 361.1433 20 multipath-exploration lexicase 0.01 indiv-rand-sample 1321.9050 1364.0055 20 multipath-exploration lexicase 0.01 phylo-informed-sample 1259.1250 1294.0110 20 multipath-exploration lexicase 0.1 down-sample 588.2735 638.4361 20 multipath-exploration lexicase 0.1 down-sample-ancestor 2532.2150 2560.9660 20 multipath-exploration lexicase 0.1 indiv-rand-sample 2295.0250 2298.3220 20 multipath-exploration lexicase 0.1 phylo-informed-sample 2579.3150 2578.1605 20 multipath-exploration lexicase 1 full 9082.8750 9012.5545 20 multipath-exploration tournament 0.01 down-sample 656.5385 772.8447 20 multipath-exploration tournament 0.01 down-sample-ancestor 547.7415 543.6774 20 multipath-exploration tournament 0.01 indiv-rand-sample 3524.0450 3413.6629 20 multipath-exploration tournament 0.01 phylo-informed-sample 2894.6900 3195.8964 20 multipath-exploration tournament 0.1 down-sample 2349.5100 2765.9270 20 multipath-exploration tournament 0.1 down-sample-ancestor 3789.5600 3862.7725 20 multipath-exploration tournament 0.1 indiv-rand-sample 5149.1700 5136.1509 20 multipath-exploration tournament 0.1 phylo-informed-sample 5449.0750 5456.4340 20 multipath-exploration tournament 1 full 4649.8450 5273.6010 20 Next, we run a Kruskal-Wallis test to check for differences. For these tests, we only compare within a single subsampling level (evals_per_gen) and within the same selection scheme. kw_test &lt;- explore_summary_data %&gt;% filter(eval_label != &quot;full&quot;) %&gt;% group_by(SELECTION, evals_per_gen) %&gt;% kruskal_test(elite_true_agg_score ~ eval_label) %&gt;% mutate(sig = (p &lt; 0.05)) %&gt;% unite( &quot;comparison_group&quot;, SELECTION, evals_per_gen, sep = &quot;_&quot;, remove = FALSE ) kable(kw_test) comparison_group SELECTION evals_per_gen .y. n statistic df p method sig lexicase_0.01 lexicase 0.01 elite_true_agg_score 80 63.64833 3 0.00e+00 Kruskal-Wallis TRUE lexicase_0.1 lexicase 0.1 elite_true_agg_score 80 48.94519 3 0.00e+00 Kruskal-Wallis TRUE tournament_0.01 tournament 0.01 elite_true_agg_score 80 30.85796 3 9.00e-07 Kruskal-Wallis TRUE tournament_0.1 tournament 0.1 elite_true_agg_score 80 10.82091 3 1.27e-02 Kruskal-Wallis TRUE # Grab group names of significant comparisons sig_kw_groups &lt;- filter(kw_test, p &lt; 0.05)$comparison_group wrs_test &lt;- explore_summary_data %&gt;% unite( &quot;comparison_group&quot;, SELECTION, evals_per_gen, sep = &quot;_&quot;, remove = FALSE ) %&gt;% filter( eval_label != &quot;full&quot; &amp; comparison_group %in% sig_kw_groups ) %&gt;% group_by(SELECTION, evals_per_gen) %&gt;% pairwise_wilcox_test(elite_true_agg_score ~ eval_label) %&gt;% adjust_pvalue(method = &quot;holm&quot;) %&gt;% add_significance(&quot;p.adj&quot;) kable(wrs_test) SELECTION evals_per_gen .y. group1 group2 n1 n2 statistic p p.adj p.adj.signif lexicase 0.01 elite_true_agg_score down-sample down-sample-ancestor 20 20 335.0 1.36e-04 0.0020400 ** lexicase 0.01 elite_true_agg_score down-sample indiv-rand-sample 20 20 0.0 0.00e+00 0.0000000 **** lexicase 0.01 elite_true_agg_score down-sample phylo-informed-sample 20 20 0.0 0.00e+00 0.0000000 **** lexicase 0.01 elite_true_agg_score down-sample-ancestor indiv-rand-sample 20 20 0.0 0.00e+00 0.0000000 **** lexicase 0.01 elite_true_agg_score down-sample-ancestor phylo-informed-sample 20 20 0.0 0.00e+00 0.0000000 **** lexicase 0.01 elite_true_agg_score indiv-rand-sample phylo-informed-sample 20 20 274.0 4.60e-02 0.3220000 ns lexicase 0.1 elite_true_agg_score down-sample down-sample-ancestor 20 20 0.0 0.00e+00 0.0000000 **** lexicase 0.1 elite_true_agg_score down-sample indiv-rand-sample 20 20 0.0 0.00e+00 0.0000000 **** lexicase 0.1 elite_true_agg_score down-sample phylo-informed-sample 20 20 0.0 0.00e+00 0.0000000 **** lexicase 0.1 elite_true_agg_score down-sample-ancestor indiv-rand-sample 20 20 302.0 5.00e-03 0.0550000 ns lexicase 0.1 elite_true_agg_score down-sample-ancestor phylo-informed-sample 20 20 190.0 7.99e-01 1.0000000 ns lexicase 0.1 elite_true_agg_score indiv-rand-sample phylo-informed-sample 20 20 122.0 3.50e-02 0.2800000 ns tournament 0.01 elite_true_agg_score down-sample down-sample-ancestor 20 20 291.0 1.30e-02 0.1170000 ns tournament 0.01 elite_true_agg_score down-sample indiv-rand-sample 20 20 65.0 1.36e-04 0.0020400 ** tournament 0.01 elite_true_agg_score down-sample phylo-informed-sample 20 20 66.0 1.55e-04 0.0020400 ** tournament 0.01 elite_true_agg_score down-sample-ancestor indiv-rand-sample 20 20 57.0 4.51e-05 0.0007216 *** tournament 0.01 elite_true_agg_score down-sample-ancestor phylo-informed-sample 20 20 53.0 2.49e-05 0.0004233 *** tournament 0.01 elite_true_agg_score indiv-rand-sample phylo-informed-sample 20 20 211.0 7.79e-01 1.0000000 ns tournament 0.1 elite_true_agg_score down-sample down-sample-ancestor 20 20 187.0 7.38e-01 1.0000000 ns tournament 0.1 elite_true_agg_score down-sample indiv-rand-sample 20 20 95.5 5.00e-03 0.0550000 ns tournament 0.1 elite_true_agg_score down-sample phylo-informed-sample 20 20 86.0 2.00e-03 0.0240000 * tournament 0.1 elite_true_agg_score down-sample-ancestor indiv-rand-sample 20 20 147.0 1.57e-01 0.8520000 ns tournament 0.1 elite_true_agg_score down-sample-ancestor phylo-informed-sample 20 20 145.0 1.42e-01 0.8520000 ns tournament 0.1 elite_true_agg_score indiv-rand-sample phylo-informed-sample 20 20 184.0 6.78e-01 1.0000000 ns 7.3.2 Over time - Lexicase selection p &lt;- ts_data %&gt;% build_plot_time_series( &quot;multipath-exploration&quot;, &quot;lexicase&quot;, &quot;max_agg_score&quot; ) ggsave( filename = paste0(plot_directory, &quot;explore-score-ts-lex.pdf&quot;), plot = p, width = 15, height = 10 ) 7.4 Manuscript figures Figures customized / cleaned up for the manuscript. build_final_score_manuscript_plot &lt;- function( selection, subsample_rate ) { # Extract median values for max aggregate score at same evaluation level as sampling regimes max_eval &lt;- max( filter(explore_ts_data, evals_per_gen == subsample_rate)$evaluations ) full_eval_steps &lt;- as.numeric( levels( as.factor( filter(explore_ts_data, eval_label == &quot;full&quot; &amp; evaluations &gt;= max_eval)$evaluations # nolint: line_length_linter. ) ) ) full_eval &lt;- full_eval_steps[which.min( full_eval_steps - max_eval )] full_median_score_evals &lt;- median( filter( explore_ts_data, SELECTION == selection &amp; eval_label == &quot;full&quot; &amp; evaluations == full_eval )$max_agg_score ) plot &lt;- explore_summary_data %&gt;% filter( eval_label != &quot;full&quot; &amp; SELECTION == selection &amp; evals_per_gen == subsample_rate ) %&gt;% ggplot( aes( x = eval_label, y = elite_true_agg_score, fill = eval_label ) ) + geom_hline( yintercept = full_median_score_evals, size = 1.0, alpha = 0.7, color = &quot;black&quot;, linetype=&quot;dashed&quot; ) + geom_flat_violin( position = position_nudge(x = .2, y = 0), alpha = .8, adjust = 1.5 ) + geom_point( mapping = aes(color = eval_label), position = position_jitter(width = .15), size = .5, alpha = 0.8 ) + geom_boxplot( width = .1, outlier.shape = NA, alpha = 0.5 ) + scale_y_continuous( name = &quot;Aggregate score&quot;, limits = c(0, 4000) ) + scale_x_discrete( name = &quot;Subsampling regime&quot;, breaks = c(&quot;down-sample&quot;, &quot;down-sample-ancestor&quot;, &quot;indiv-rand-sample&quot;, &quot;phylo-informed-sample&quot;), labels = c(&quot;DS&quot;, &quot;DS+EST&quot;, &quot;IRS&quot;, &quot;ABS&quot;) ) + scale_fill_bright() + scale_color_bright() + theme( legend.position = &quot;none&quot;, # axis.text.x = element_text( # angle = 30, # hjust = 1 # ), ) return(plot) } Build end-of-run plots (fixed number of evaluations) plot_final_lex_01 &lt;- build_final_score_manuscript_plot( &quot;lexicase&quot;, &quot;0.01&quot; ) plot_final_lex_10 &lt;- build_final_score_manuscript_plot( &quot;lexicase&quot;, &quot;0.1&quot; ) Combine into single figure lex_fig &lt;- plot_grid( plot_final_lex_01 + theme( plot.margin = margin(1, 0, 0, 0, &quot;cm&quot;) ), plot_final_lex_10 + theme( axis.text.y = element_blank(), axis.title.y = element_blank(), axis.ticks.y = element_blank(), plot.margin = margin(1, 0, 0, 1, &quot;cm&quot;) ), nrow = 1, ncol = 2, align = &quot;h&quot;, labels = c(&quot;a) 1% subsampling&quot;, &quot;b) 10% subsampling&quot;), rel_widths = c(1, 1) ) lex_fig save_plot( filename = paste0(plot_directory, &quot;2023-12-28-explore-lex-fig.pdf&quot;), plot = lex_fig, base_width = 7, base_height = 3, dpi = 600 ) "],["program-synthesis-experiments.html", "Chapter 8 Program synthesis experiments 8.1 Dependencies 8.2 Setup 8.3 Problem-solving success statistics 8.4 Average number of unique candidates selected", " Chapter 8 Program synthesis experiments experiment_slug &lt;- &quot;2023-12-30-psynth&quot; working_directory &lt;- paste0( &quot;experiments/&quot;, experiment_slug, &quot;/analysis/&quot; ) if (exists(&quot;bookdown_wd_prefix&quot;)) { working_directory &lt;- paste0( bookdown_wd_prefix, working_directory ) } 8.1 Dependencies library(tidyverse) library(ggplot2) library(cowplot) library(RColorBrewer) library(khroma) library(rstatix) library(knitr) library(kableExtra) ## ## Attaching package: &#39;kableExtra&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## group_rows source(&quot;https://gist.githubusercontent.com/benmarwick/2a1bb0133ff568cbe28d/raw/fb53bd97121f7f9ce947837ef1a4c65a73bffb3f/geom_flat_violin.R&quot;) print(version) ## _ ## platform aarch64-apple-darwin20 ## arch aarch64 ## os darwin20 ## system aarch64, darwin20 ## status ## major 4 ## minor 2.1 ## year 2022 ## month 06 ## day 23 ## svn rev 82513 ## language R ## version.string R version 4.2.1 (2022-06-23) ## nickname Funny-Looking Kid 8.2 Setup # Configure our default graphing theme theme_set(theme_cowplot()) # Create a directory to store plots plot_directory &lt;- paste0(working_directory, &quot;plots/&quot;) dir.create(plot_directory, showWarnings=FALSE) 8.2.1 Load summary data summary_data_loc &lt;- paste0(working_directory, &quot;data/aggregate.csv&quot;) summary_data &lt;- read_csv(summary_data_loc) ## Rows: 5000 Columns: 73 ## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (11): ANCESTOR_FILE_PATH, EVAL_FIT_EST_MODE, EVAL_MODE, POP_INIT_MODE, P... ## dbl (62): EVAL_CPU_CYCLES_PER_TEST, EVAL_MAX_PHYLO_SEARCH_DEPTH, MAX_ACTIVE_... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. summary_data &lt;- summary_data %&gt;% mutate( eval_mode_row = case_when( EVAL_MODE == &quot;full&quot; &amp; TEST_DOWNSAMPLE_RATE == &quot;1&quot; ~ &quot;down-sample&quot;, EVAL_MODE == &quot;full&quot; &amp; NUM_COHORTS == &quot;1&quot; ~ &quot;cohort&quot;, .default = EVAL_MODE ), evals_per_gen = case_when( EVAL_MODE == &quot;cohort&quot; ~ 1.0 / NUM_COHORTS, EVAL_MODE == &quot;down-sample&quot; ~ TEST_DOWNSAMPLE_RATE, EVAL_MODE == &quot;indiv-rand-sample&quot; ~ TEST_DOWNSAMPLE_RATE, EVAL_MODE == &quot;phylo-informed-sample&quot; ~ TEST_DOWNSAMPLE_RATE, EVAL_MODE == &quot;full&quot; ~ 1.0 ), EVAL_FIT_EST_MODE = case_when( EVAL_FIT_EST_MODE == &quot;ancestor-opt&quot; ~ &quot;ancestor&quot;, EVAL_FIT_EST_MODE == &quot;relative-opt&quot; ~ &quot;relative&quot;, .default = EVAL_FIT_EST_MODE ), est_mode_with_depth = paste( EVAL_FIT_EST_MODE, EVAL_MAX_PHYLO_SEARCH_DEPTH, sep = &quot;-&quot; ), eval_mode_est_mode_depth = paste( EVAL_MODE, EVAL_FIT_EST_MODE, EVAL_MAX_PHYLO_SEARCH_DEPTH, sep = &quot;-&quot; ), .keep = &quot;all&quot; ) %&gt;% mutate( eval_label = case_when( # Clean up down-sample label EVAL_MODE == &quot;down-sample&quot; &amp; EVAL_FIT_EST_MODE != &quot;none&quot; ~ paste(&quot;down-sample&quot;, EVAL_FIT_EST_MODE, sep=&quot;-&quot;), .default = EVAL_MODE ), ) %&gt;% mutate( evals_per_gen = as.factor(evals_per_gen), est_mode_with_depth = as.factor(est_mode_with_depth), eval_mode_est_mode_depth = as.factor(eval_mode_est_mode_depth), EVAL_MAX_PHYLO_SEARCH_DEPTH = as.factor(EVAL_MAX_PHYLO_SEARCH_DEPTH), PROBLEM = as.factor(PROBLEM), SELECTION = as.factor(SELECTION), EVAL_MODE = as.factor(EVAL_MODE), NUM_COHORTS = as.factor(NUM_COHORTS), TEST_DOWNSAMPLE_RATE = as.factor(TEST_DOWNSAMPLE_RATE), EVAL_FIT_EST_MODE = factor( EVAL_FIT_EST_MODE, levels = c( &quot;none&quot;, &quot;ancestor&quot;, &quot;relative&quot; ), labels = c( &quot;None&quot;, &quot;Ancestor&quot;, &quot;Relative&quot; ) ), .keep = &quot;all&quot; ) solution_counts &lt;- summary_data %&gt;% group_by( PROBLEM, evals_per_gen, eval_mode_row, EVAL_FIT_EST_MODE, est_mode_with_depth, eval_mode_est_mode_depth, EVAL_MODE, eval_label, EVAL_MAX_PHYLO_SEARCH_DEPTH ) %&gt;% summarize( solution_count = sum(found_solution == &quot;1&quot;), replicates = n(), no_solution_count = n() - sum(found_solution == &quot;1&quot;) ) ## `summarise()` has grouped output by &#39;PROBLEM&#39;, &#39;evals_per_gen&#39;, &#39;eval_mode_row&#39;, &#39;EVAL_FIT_EST_MODE&#39;, &#39;est_mode_with_depth&#39;, &#39;eval_mode_est_mode_depth&#39;, &#39;EVAL_MODE&#39;, &#39;eval_label&#39;. You can override using ## the `.groups` argument. # print(solution_counts, n=208) solution_table &lt;- kable(solution_counts) %&gt;% kable_styling(latex_options = &quot;striped&quot;, font_size = 25) save_kable(solution_table, paste0(plot_directory, &quot;solution_counts_table.pdf&quot;)) ## Note that HTML color may not be displayed on PDF properly. solution_table PROBLEM evals_per_gen eval_mode_row EVAL_FIT_EST_MODE est_mode_with_depth eval_mode_est_mode_depth EVAL_MODE eval_label EVAL_MAX_PHYLO_SEARCH_DEPTH solution_count replicates no_solution_count bouncing-balls 0.01 down-sample None none-1 down-sample-none-1 down-sample down-sample 1 1 50 49 bouncing-balls 0.01 down-sample Ancestor ancestor-8 down-sample-ancestor-8 down-sample down-sample-ancestor 8 8 50 42 bouncing-balls 0.01 indiv-rand-sample Ancestor ancestor-8 indiv-rand-sample-ancestor-8 indiv-rand-sample indiv-rand-sample 8 7 50 43 bouncing-balls 0.01 phylo-informed-sample Ancestor ancestor-8 phylo-informed-sample-ancestor-8 phylo-informed-sample phylo-informed-sample 8 4 50 46 bouncing-balls 0.1 down-sample None none-1 down-sample-none-1 down-sample down-sample 1 0 50 50 bouncing-balls 0.1 down-sample Ancestor ancestor-8 down-sample-ancestor-8 down-sample down-sample-ancestor 8 4 50 46 bouncing-balls 0.1 indiv-rand-sample Ancestor ancestor-8 indiv-rand-sample-ancestor-8 indiv-rand-sample indiv-rand-sample 8 2 50 48 bouncing-balls 0.1 phylo-informed-sample Ancestor ancestor-8 phylo-informed-sample-ancestor-8 phylo-informed-sample phylo-informed-sample 8 3 50 47 bouncing-balls 1 full None none-1 full-none-1 full full 1 0 100 100 dice-game 0.01 down-sample None none-1 down-sample-none-1 down-sample down-sample 1 0 50 50 dice-game 0.01 down-sample Ancestor ancestor-8 down-sample-ancestor-8 down-sample down-sample-ancestor 8 26 50 24 dice-game 0.01 indiv-rand-sample Ancestor ancestor-8 indiv-rand-sample-ancestor-8 indiv-rand-sample indiv-rand-sample 8 25 50 25 dice-game 0.01 phylo-informed-sample Ancestor ancestor-8 phylo-informed-sample-ancestor-8 phylo-informed-sample phylo-informed-sample 8 31 50 19 dice-game 0.1 down-sample None none-1 down-sample-none-1 down-sample down-sample 1 18 50 32 dice-game 0.1 down-sample Ancestor ancestor-8 down-sample-ancestor-8 down-sample down-sample-ancestor 8 19 50 31 dice-game 0.1 indiv-rand-sample Ancestor ancestor-8 indiv-rand-sample-ancestor-8 indiv-rand-sample indiv-rand-sample 8 14 50 36 dice-game 0.1 phylo-informed-sample Ancestor ancestor-8 phylo-informed-sample-ancestor-8 phylo-informed-sample phylo-informed-sample 8 18 50 32 dice-game 1 full None none-1 full-none-1 full full 1 0 100 100 fizz-buzz 0.01 down-sample None none-1 down-sample-none-1 down-sample down-sample 1 5 50 45 fizz-buzz 0.01 down-sample Ancestor ancestor-8 down-sample-ancestor-8 down-sample down-sample-ancestor 8 10 50 40 fizz-buzz 0.01 indiv-rand-sample Ancestor ancestor-8 indiv-rand-sample-ancestor-8 indiv-rand-sample indiv-rand-sample 8 26 50 24 fizz-buzz 0.01 phylo-informed-sample Ancestor ancestor-8 phylo-informed-sample-ancestor-8 phylo-informed-sample phylo-informed-sample 8 30 50 20 fizz-buzz 0.1 down-sample None none-1 down-sample-none-1 down-sample down-sample 1 39 50 11 fizz-buzz 0.1 down-sample Ancestor ancestor-8 down-sample-ancestor-8 down-sample down-sample-ancestor 8 41 50 9 fizz-buzz 0.1 indiv-rand-sample Ancestor ancestor-8 indiv-rand-sample-ancestor-8 indiv-rand-sample indiv-rand-sample 8 19 50 31 fizz-buzz 0.1 phylo-informed-sample Ancestor ancestor-8 phylo-informed-sample-ancestor-8 phylo-informed-sample phylo-informed-sample 8 24 50 26 fizz-buzz 1 full None none-1 full-none-1 full full 1 9 100 91 for-loop-index 0.01 down-sample None none-1 down-sample-none-1 down-sample down-sample 1 6 50 44 for-loop-index 0.01 down-sample Ancestor ancestor-8 down-sample-ancestor-8 down-sample down-sample-ancestor 8 44 50 6 for-loop-index 0.01 indiv-rand-sample Ancestor ancestor-8 indiv-rand-sample-ancestor-8 indiv-rand-sample indiv-rand-sample 8 49 50 1 for-loop-index 0.01 phylo-informed-sample Ancestor ancestor-8 phylo-informed-sample-ancestor-8 phylo-informed-sample phylo-informed-sample 8 50 50 0 for-loop-index 0.1 down-sample None none-1 down-sample-none-1 down-sample down-sample 1 29 50 21 for-loop-index 0.1 down-sample Ancestor ancestor-8 down-sample-ancestor-8 down-sample down-sample-ancestor 8 35 50 15 for-loop-index 0.1 indiv-rand-sample Ancestor ancestor-8 indiv-rand-sample-ancestor-8 indiv-rand-sample indiv-rand-sample 8 32 50 18 for-loop-index 0.1 phylo-informed-sample Ancestor ancestor-8 phylo-informed-sample-ancestor-8 phylo-informed-sample phylo-informed-sample 8 27 50 23 for-loop-index 1 full None none-1 full-none-1 full full 1 24 100 76 gcd 0.01 down-sample None none-1 down-sample-none-1 down-sample down-sample 1 0 50 50 gcd 0.01 down-sample Ancestor ancestor-8 down-sample-ancestor-8 down-sample down-sample-ancestor 8 12 50 38 gcd 0.01 indiv-rand-sample Ancestor ancestor-8 indiv-rand-sample-ancestor-8 indiv-rand-sample indiv-rand-sample 8 18 50 32 gcd 0.01 phylo-informed-sample Ancestor ancestor-8 phylo-informed-sample-ancestor-8 phylo-informed-sample phylo-informed-sample 8 21 50 29 gcd 0.1 down-sample None none-1 down-sample-none-1 down-sample down-sample 1 2 50 48 gcd 0.1 down-sample Ancestor ancestor-8 down-sample-ancestor-8 down-sample down-sample-ancestor 8 11 50 39 gcd 0.1 indiv-rand-sample Ancestor ancestor-8 indiv-rand-sample-ancestor-8 indiv-rand-sample indiv-rand-sample 8 12 50 38 gcd 0.1 phylo-informed-sample Ancestor ancestor-8 phylo-informed-sample-ancestor-8 phylo-informed-sample phylo-informed-sample 8 12 50 38 gcd 1 full None none-1 full-none-1 full full 1 1 100 99 grade 0.01 down-sample None none-1 down-sample-none-1 down-sample down-sample 1 2 50 48 grade 0.01 down-sample Ancestor ancestor-8 down-sample-ancestor-8 down-sample down-sample-ancestor 8 35 50 15 grade 0.01 indiv-rand-sample Ancestor ancestor-8 indiv-rand-sample-ancestor-8 indiv-rand-sample indiv-rand-sample 8 40 50 10 grade 0.01 phylo-informed-sample Ancestor ancestor-8 phylo-informed-sample-ancestor-8 phylo-informed-sample phylo-informed-sample 8 41 50 9 grade 0.1 down-sample None none-1 down-sample-none-1 down-sample down-sample 1 46 50 4 grade 0.1 down-sample Ancestor ancestor-8 down-sample-ancestor-8 down-sample down-sample-ancestor 8 40 50 10 grade 0.1 indiv-rand-sample Ancestor ancestor-8 indiv-rand-sample-ancestor-8 indiv-rand-sample indiv-rand-sample 8 35 50 15 grade 0.1 phylo-informed-sample Ancestor ancestor-8 phylo-informed-sample-ancestor-8 phylo-informed-sample phylo-informed-sample 8 29 50 21 grade 1 full None none-1 full-none-1 full full 1 22 100 78 median 0.01 down-sample None none-1 down-sample-none-1 down-sample down-sample 1 50 50 0 median 0.01 down-sample Ancestor ancestor-8 down-sample-ancestor-8 down-sample down-sample-ancestor 8 40 50 10 median 0.01 indiv-rand-sample Ancestor ancestor-8 indiv-rand-sample-ancestor-8 indiv-rand-sample indiv-rand-sample 8 45 50 5 median 0.01 phylo-informed-sample Ancestor ancestor-8 phylo-informed-sample-ancestor-8 phylo-informed-sample phylo-informed-sample 8 47 50 3 median 0.1 down-sample None none-1 down-sample-none-1 down-sample down-sample 1 47 50 3 median 0.1 down-sample Ancestor ancestor-8 down-sample-ancestor-8 down-sample down-sample-ancestor 8 45 50 5 median 0.1 indiv-rand-sample Ancestor ancestor-8 indiv-rand-sample-ancestor-8 indiv-rand-sample indiv-rand-sample 8 47 50 3 median 0.1 phylo-informed-sample Ancestor ancestor-8 phylo-informed-sample-ancestor-8 phylo-informed-sample phylo-informed-sample 8 40 50 10 median 1 full None none-1 full-none-1 full full 1 34 100 66 small-or-large 0.01 down-sample None none-1 down-sample-none-1 down-sample down-sample 1 11 50 39 small-or-large 0.01 down-sample Ancestor ancestor-8 down-sample-ancestor-8 down-sample down-sample-ancestor 8 8 50 42 small-or-large 0.01 indiv-rand-sample Ancestor ancestor-8 indiv-rand-sample-ancestor-8 indiv-rand-sample indiv-rand-sample 8 16 50 34 small-or-large 0.01 phylo-informed-sample Ancestor ancestor-8 phylo-informed-sample-ancestor-8 phylo-informed-sample phylo-informed-sample 8 14 50 36 small-or-large 0.1 down-sample None none-1 down-sample-none-1 down-sample down-sample 1 28 50 22 small-or-large 0.1 down-sample Ancestor ancestor-8 down-sample-ancestor-8 down-sample down-sample-ancestor 8 21 50 29 small-or-large 0.1 indiv-rand-sample Ancestor ancestor-8 indiv-rand-sample-ancestor-8 indiv-rand-sample indiv-rand-sample 8 8 50 42 small-or-large 0.1 phylo-informed-sample Ancestor ancestor-8 phylo-informed-sample-ancestor-8 phylo-informed-sample phylo-informed-sample 8 12 50 38 small-or-large 1 full None none-1 full-none-1 full full 1 4 100 96 smallest 0.01 down-sample None none-1 down-sample-none-1 down-sample down-sample 1 49 50 1 smallest 0.01 down-sample Ancestor ancestor-8 down-sample-ancestor-8 down-sample down-sample-ancestor 8 47 50 3 smallest 0.01 indiv-rand-sample Ancestor ancestor-8 indiv-rand-sample-ancestor-8 indiv-rand-sample indiv-rand-sample 8 50 50 0 smallest 0.01 phylo-informed-sample Ancestor ancestor-8 phylo-informed-sample-ancestor-8 phylo-informed-sample phylo-informed-sample 8 50 50 0 smallest 0.1 down-sample None none-1 down-sample-none-1 down-sample down-sample 1 47 50 3 smallest 0.1 down-sample Ancestor ancestor-8 down-sample-ancestor-8 down-sample down-sample-ancestor 8 47 50 3 smallest 0.1 indiv-rand-sample Ancestor ancestor-8 indiv-rand-sample-ancestor-8 indiv-rand-sample indiv-rand-sample 8 49 50 1 smallest 0.1 phylo-informed-sample Ancestor ancestor-8 phylo-informed-sample-ancestor-8 phylo-informed-sample phylo-informed-sample 8 49 50 1 smallest 1 full None none-1 full-none-1 full full 1 51 100 49 snow-day 0.01 down-sample None none-1 down-sample-none-1 down-sample down-sample 1 0 50 50 snow-day 0.01 down-sample Ancestor ancestor-8 down-sample-ancestor-8 down-sample down-sample-ancestor 8 3 50 47 snow-day 0.01 indiv-rand-sample Ancestor ancestor-8 indiv-rand-sample-ancestor-8 indiv-rand-sample indiv-rand-sample 8 1 50 49 snow-day 0.01 phylo-informed-sample Ancestor ancestor-8 phylo-informed-sample-ancestor-8 phylo-informed-sample phylo-informed-sample 8 1 50 49 snow-day 0.1 down-sample None none-1 down-sample-none-1 down-sample down-sample 1 0 50 50 snow-day 0.1 down-sample Ancestor ancestor-8 down-sample-ancestor-8 down-sample down-sample-ancestor 8 0 50 50 snow-day 0.1 indiv-rand-sample Ancestor ancestor-8 indiv-rand-sample-ancestor-8 indiv-rand-sample indiv-rand-sample 8 1 50 49 snow-day 0.1 phylo-informed-sample Ancestor ancestor-8 phylo-informed-sample-ancestor-8 phylo-informed-sample phylo-informed-sample 8 4 50 46 snow-day 1 full None none-1 full-none-1 full full 1 0 100 100 # Summarize avg num selected # -- Not totally great because weird stuff happens when a solution is found (population collapses, etc) ts_data_loc &lt;- paste0(working_directory, &quot;data/time_series.csv&quot;) ts_data &lt;- read_csv(ts_data_loc) ## Rows: 99773 Columns: 24 ## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (6): EVAL_FIT_EST_MODE, EVAL_MODE, PROBLEM, SELECTION, TESTING_SET_PATH... ## dbl (18): EVAL_MAX_PHYLO_SEARCH_DEPTH, NUM_COHORTS, SEED, TEST_DOWNSAMPLE_RA... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. ts_data &lt;- ts_data %&gt;% mutate( eval_mode_row = case_when( EVAL_MODE == &quot;full&quot; &amp; TEST_DOWNSAMPLE_RATE == &quot;1&quot; ~ &quot;down-sample&quot;, EVAL_MODE == &quot;full&quot; &amp; NUM_COHORTS == &quot;1&quot; ~ &quot;cohort&quot;, .default = EVAL_MODE ), evals_per_gen = case_when( EVAL_MODE == &quot;cohort&quot; ~ 1.0 / NUM_COHORTS, EVAL_MODE == &quot;down-sample&quot; ~ TEST_DOWNSAMPLE_RATE, EVAL_MODE == &quot;indiv-rand-sample&quot; ~ TEST_DOWNSAMPLE_RATE, EVAL_MODE == &quot;phylo-informed-sample&quot; ~ TEST_DOWNSAMPLE_RATE, EVAL_MODE == &quot;full&quot; ~ 1.0 ), EVAL_FIT_EST_MODE = case_when( EVAL_FIT_EST_MODE == &quot;ancestor-opt&quot; ~ &quot;ancestor&quot;, EVAL_FIT_EST_MODE == &quot;relative-opt&quot; ~ &quot;relative&quot;, .default = EVAL_FIT_EST_MODE ), est_mode_with_depth = paste( EVAL_FIT_EST_MODE, EVAL_MAX_PHYLO_SEARCH_DEPTH, sep = &quot;-&quot; ), eval_mode_est_mode_depth = paste( EVAL_MODE, EVAL_FIT_EST_MODE, EVAL_MAX_PHYLO_SEARCH_DEPTH, sep = &quot;-&quot; ), .keep = &quot;all&quot; ) %&gt;% mutate( eval_label = case_when( # Clean up down-sample label EVAL_MODE == &quot;down-sample&quot; &amp; EVAL_FIT_EST_MODE != &quot;none&quot; ~ paste(&quot;down-sample&quot;, EVAL_FIT_EST_MODE, sep=&quot;-&quot;), .default = EVAL_MODE ), ) %&gt;% mutate( evals_per_gen = as.factor(evals_per_gen), est_mode_with_depth = as.factor(est_mode_with_depth), eval_mode_est_mode_depth = as.factor(eval_mode_est_mode_depth), EVAL_MAX_PHYLO_SEARCH_DEPTH = as.factor(EVAL_MAX_PHYLO_SEARCH_DEPTH), PROBLEM = as.factor(PROBLEM), SELECTION = as.factor(SELECTION), EVAL_MODE = as.factor(EVAL_MODE), NUM_COHORTS = as.factor(NUM_COHORTS), TEST_DOWNSAMPLE_RATE = as.factor(TEST_DOWNSAMPLE_RATE), EVAL_FIT_EST_MODE = factor( EVAL_FIT_EST_MODE, levels = c( &quot;none&quot;, &quot;ancestor&quot;, &quot;relative&quot; ), labels = c( &quot;None&quot;, &quot;Ancestor&quot;, &quot;Relative&quot; ) ), .keep = &quot;all&quot; ) ts_avgs &lt;- ts_data %&gt;% group_by( SEED, eval_label, evals_per_gen, PROBLEM ) %&gt;% summarize( n = n(), avg_num_unique_selected = mean(num_unique_selected), avg_entropy_selected_ids = mean(entropy_selected_ids) ) %&gt;% mutate( eval_label = as.factor(eval_label), evals_per_gen = as.factor(evals_per_gen), PROBLEM = as.factor(PROBLEM) ) ## `summarise()` has grouped output by &#39;SEED&#39;, &#39;eval_label&#39;, &#39;evals_per_gen&#39;. You ## can override using the `.groups` argument. 8.3 Problem-solving success statistics sol_stats_data &lt;- solution_counts %&gt;% filter(EVAL_MODE != &quot;full&quot;) %&gt;% ungroup() %&gt;% unite( &quot;grouping&quot;, PROBLEM, evals_per_gen, sep=&quot;_&quot; ) %&gt;% select( grouping, eval_label, solution_count, no_solution_count ) %&gt;% mutate( grouping = as.factor(grouping) ) fisher_results &lt;- data.frame( comparison = character(), group1 = character(), group2 = character(), n = integer(), p = double(), p.adj = double(), p.adj.signif = character() ) groupings &lt;- levels(sol_stats_data$grouping) for (g in groupings) { ft_results &lt;- sol_stats_data %&gt;% filter(grouping == g) %&gt;% select(!grouping) %&gt;% column_to_rownames(var = &quot;eval_label&quot;) %&gt;% pairwise_fisher_test( p.adjust.method = &quot;holm&quot; ) %&gt;% add_significance(&quot;p.adj&quot;) ft_results &lt;- ft_results %&gt;% mutate( comparison = rep(g, nrow(ft_results)), .keep = &quot;all&quot; ) %&gt;% relocate(comparison) fisher_results &lt;- rbind( fisher_results, ft_results ) } fisher_results &lt;- as.tibble(fisher_results) ## Warning: `as.tibble()` was deprecated in tibble 2.0.0. ## ℹ Please use `as_tibble()` instead. ## ℹ The signature and semantics have changed, see `?as_tibble`. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. fisher_results &lt;- fisher_results %&gt;% mutate( comparison = as.factor(comparison), group1 = as.factor(group1), group2 = as.factor(group2), ) %&gt;% group_by( comparison ) fisher_table &lt;- kbl(fisher_results) %&gt;% kable_styling() save_kable(fisher_table, paste0(plot_directory, &quot;stats_table.pdf&quot;)) ## Note that HTML color may not be displayed on PDF properly. fisher_table comparison group1 group2 n p p.adj p.adj.signif bouncing-balls_0.01 down-sample down-sample-ancestor 100 3.09e-02 1.85e-01 ns bouncing-balls_0.01 down-sample indiv-rand-sample 100 5.94e-02 2.97e-01 ns bouncing-balls_0.01 down-sample phylo-informed-sample 100 3.62e-01 1.00e+00 ns bouncing-balls_0.01 down-sample-ancestor indiv-rand-sample 100 1.00e+00 1.00e+00 ns bouncing-balls_0.01 down-sample-ancestor phylo-informed-sample 100 3.57e-01 1.00e+00 ns bouncing-balls_0.01 indiv-rand-sample phylo-informed-sample 100 5.25e-01 1.00e+00 ns bouncing-balls_0.1 down-sample down-sample-ancestor 100 1.17e-01 7.02e-01 ns bouncing-balls_0.1 down-sample indiv-rand-sample 100 4.95e-01 1.00e+00 ns bouncing-balls_0.1 down-sample phylo-informed-sample 100 2.42e-01 1.00e+00 ns bouncing-balls_0.1 down-sample-ancestor indiv-rand-sample 100 6.78e-01 1.00e+00 ns bouncing-balls_0.1 down-sample-ancestor phylo-informed-sample 100 1.00e+00 1.00e+00 ns bouncing-balls_0.1 indiv-rand-sample phylo-informed-sample 100 1.00e+00 1.00e+00 ns dice-game_0.01 down-sample down-sample-ancestor 100 0.00e+00 0.00e+00 **** dice-game_0.01 down-sample indiv-rand-sample 100 0.00e+00 0.00e+00 **** dice-game_0.01 down-sample phylo-informed-sample 100 0.00e+00 0.00e+00 **** dice-game_0.01 down-sample-ancestor indiv-rand-sample 100 1.00e+00 1.00e+00 ns dice-game_0.01 down-sample-ancestor phylo-informed-sample 100 4.19e-01 9.42e-01 ns dice-game_0.01 indiv-rand-sample phylo-informed-sample 100 3.14e-01 9.42e-01 ns dice-game_0.1 down-sample down-sample-ancestor 100 1.00e+00 1.00e+00 ns dice-game_0.1 down-sample indiv-rand-sample 100 5.21e-01 1.00e+00 ns dice-game_0.1 down-sample phylo-informed-sample 100 1.00e+00 1.00e+00 ns dice-game_0.1 down-sample-ancestor indiv-rand-sample 100 3.95e-01 1.00e+00 ns dice-game_0.1 down-sample-ancestor phylo-informed-sample 100 1.00e+00 1.00e+00 ns dice-game_0.1 indiv-rand-sample phylo-informed-sample 100 5.21e-01 1.00e+00 ns fizz-buzz_0.01 down-sample down-sample-ancestor 100 2.62e-01 5.24e-01 ns fizz-buzz_0.01 down-sample indiv-rand-sample 100 8.60e-06 4.28e-05 **** fizz-buzz_0.01 down-sample phylo-informed-sample 100 2.00e-07 1.20e-06 **** fizz-buzz_0.01 down-sample-ancestor indiv-rand-sample 100 1.59e-03 4.77e-03 ** fizz-buzz_0.01 down-sample-ancestor phylo-informed-sample 100 8.31e-05 3.32e-04 *** fizz-buzz_0.01 indiv-rand-sample phylo-informed-sample 100 5.46e-01 5.46e-01 ns fizz-buzz_0.1 down-sample down-sample-ancestor 100 8.03e-01 8.38e-01 ns fizz-buzz_0.1 down-sample indiv-rand-sample 100 9.55e-05 4.78e-04 *** fizz-buzz_0.1 down-sample phylo-informed-sample 100 3.46e-03 1.04e-02 fizz-buzz_0.1 down-sample-ancestor indiv-rand-sample 100 1.26e-05 7.56e-05 **** fizz-buzz_0.1 down-sample-ancestor phylo-informed-sample 100 6.80e-04 2.72e-03 ** fizz-buzz_0.1 indiv-rand-sample phylo-informed-sample 100 4.19e-01 8.38e-01 ns for-loop-index_0.01 down-sample down-sample-ancestor 100 0.00e+00 0.00e+00 **** for-loop-index_0.01 down-sample indiv-rand-sample 100 0.00e+00 0.00e+00 **** for-loop-index_0.01 down-sample phylo-informed-sample 100 0.00e+00 0.00e+00 **** for-loop-index_0.01 down-sample-ancestor indiv-rand-sample 100 1.12e-01 2.24e-01 ns for-loop-index_0.01 down-sample-ancestor phylo-informed-sample 100 2.67e-02 8.01e-02 ns for-loop-index_0.01 indiv-rand-sample phylo-informed-sample 100 1.00e+00 1.00e+00 ns for-loop-index_0.1 down-sample down-sample-ancestor 100 2.98e-01 1.00e+00 ns for-loop-index_0.1 down-sample indiv-rand-sample 100 6.82e-01 1.00e+00 ns for-loop-index_0.1 down-sample phylo-informed-sample 100 8.40e-01 1.00e+00 ns for-loop-index_0.1 down-sample-ancestor indiv-rand-sample 100 6.71e-01 1.00e+00 ns for-loop-index_0.1 down-sample-ancestor phylo-informed-sample 100 1.49e-01 8.94e-01 ns for-loop-index_0.1 indiv-rand-sample phylo-informed-sample 100 4.16e-01 1.00e+00 ns gcd_0.01 down-sample down-sample-ancestor 100 2.31e-04 9.24e-04 *** gcd_0.01 down-sample indiv-rand-sample 100 1.20e-06 5.90e-06 **** gcd_0.01 down-sample phylo-informed-sample 100 1.00e-07 4.00e-07 **** gcd_0.01 down-sample-ancestor indiv-rand-sample 100 2.75e-01 5.50e-01 ns gcd_0.01 down-sample-ancestor phylo-informed-sample 100 8.81e-02 2.64e-01 ns gcd_0.01 indiv-rand-sample phylo-informed-sample 100 6.82e-01 6.82e-01 ns gcd_0.1 down-sample down-sample-ancestor 100 1.47e-02 5.88e-02 ns gcd_0.1 down-sample indiv-rand-sample 100 7.58e-03 4.55e-02 gcd_0.1 down-sample phylo-informed-sample 100 7.58e-03 4.55e-02 gcd_0.1 down-sample-ancestor indiv-rand-sample 100 1.00e+00 1.00e+00 ns gcd_0.1 down-sample-ancestor phylo-informed-sample 100 1.00e+00 1.00e+00 ns gcd_0.1 indiv-rand-sample phylo-informed-sample 100 1.00e+00 1.00e+00 ns grade_0.01 down-sample down-sample-ancestor 100 0.00e+00 0.00e+00 **** grade_0.01 down-sample indiv-rand-sample 100 0.00e+00 0.00e+00 **** grade_0.01 down-sample phylo-informed-sample 100 0.00e+00 0.00e+00 **** grade_0.01 down-sample-ancestor indiv-rand-sample 100 3.56e-01 7.23e-01 ns grade_0.01 down-sample-ancestor phylo-informed-sample 100 2.41e-01 7.23e-01 ns grade_0.01 indiv-rand-sample phylo-informed-sample 100 1.00e+00 1.00e+00 ns grade_0.1 down-sample down-sample-ancestor 100 1.48e-01 4.44e-01 ns grade_0.1 down-sample indiv-rand-sample 100 9.49e-03 4.74e-02 grade_0.1 down-sample phylo-informed-sample 100 1.43e-04 8.58e-04 *** grade_0.1 down-sample-ancestor indiv-rand-sample 100 3.56e-01 5.96e-01 ns grade_0.1 down-sample-ancestor phylo-informed-sample 100 2.97e-02 1.19e-01 ns grade_0.1 indiv-rand-sample phylo-informed-sample 100 2.98e-01 5.96e-01 ns median_0.01 down-sample down-sample-ancestor 100 1.19e-03 7.14e-03 ** median_0.01 down-sample indiv-rand-sample 100 5.63e-02 2.82e-01 ns median_0.01 down-sample phylo-informed-sample 100 2.42e-01 7.26e-01 ns median_0.01 down-sample-ancestor indiv-rand-sample 100 2.62e-01 7.26e-01 ns median_0.01 down-sample-ancestor phylo-informed-sample 100 7.13e-02 2.85e-01 ns median_0.01 indiv-rand-sample phylo-informed-sample 100 7.15e-01 7.26e-01 ns median_0.1 down-sample down-sample-ancestor 100 7.15e-01 1.00e+00 ns median_0.1 down-sample indiv-rand-sample 100 1.00e+00 1.00e+00 ns median_0.1 down-sample phylo-informed-sample 100 7.13e-02 4.28e-01 ns median_0.1 down-sample-ancestor indiv-rand-sample 100 7.15e-01 1.00e+00 ns median_0.1 down-sample-ancestor phylo-informed-sample 100 2.62e-01 1.00e+00 ns median_0.1 indiv-rand-sample phylo-informed-sample 100 7.13e-02 4.28e-01 ns small-or-large_0.01 down-sample down-sample-ancestor 100 6.11e-01 1.00e+00 ns small-or-large_0.01 down-sample indiv-rand-sample 100 3.68e-01 1.00e+00 ns small-or-large_0.01 down-sample phylo-informed-sample 100 6.45e-01 1.00e+00 ns small-or-large_0.01 down-sample-ancestor indiv-rand-sample 100 1.00e-01 6.00e-01 ns small-or-large_0.01 down-sample-ancestor phylo-informed-sample 100 2.27e-01 1.00e+00 ns small-or-large_0.01 indiv-rand-sample phylo-informed-sample 100 8.28e-01 1.00e+00 ns small-or-large_0.1 down-sample down-sample-ancestor 100 2.30e-01 4.60e-01 ns small-or-large_0.1 down-sample indiv-rand-sample 100 5.58e-05 3.35e-04 *** small-or-large_0.1 down-sample phylo-informed-sample 100 2.02e-03 1.01e-02 small-or-large_0.1 down-sample-ancestor indiv-rand-sample 100 7.58e-03 3.03e-02 small-or-large_0.1 down-sample-ancestor phylo-informed-sample 100 8.81e-02 2.64e-01 ns small-or-large_0.1 indiv-rand-sample phylo-informed-sample 100 4.54e-01 4.60e-01 ns smallest_0.01 down-sample down-sample-ancestor 100 6.17e-01 1.00e+00 ns smallest_0.01 down-sample indiv-rand-sample 100 1.00e+00 1.00e+00 ns smallest_0.01 down-sample phylo-informed-sample 100 1.00e+00 1.00e+00 ns smallest_0.01 down-sample-ancestor indiv-rand-sample 100 2.42e-01 1.00e+00 ns smallest_0.01 down-sample-ancestor phylo-informed-sample 100 2.42e-01 1.00e+00 ns smallest_0.01 indiv-rand-sample phylo-informed-sample 100 1.00e+00 1.00e+00 ns smallest_0.1 down-sample down-sample-ancestor 100 1.00e+00 1.00e+00 ns smallest_0.1 down-sample indiv-rand-sample 100 6.17e-01 1.00e+00 ns smallest_0.1 down-sample phylo-informed-sample 100 6.17e-01 1.00e+00 ns smallest_0.1 down-sample-ancestor indiv-rand-sample 100 6.17e-01 1.00e+00 ns smallest_0.1 down-sample-ancestor phylo-informed-sample 100 6.17e-01 1.00e+00 ns smallest_0.1 indiv-rand-sample phylo-informed-sample 100 1.00e+00 1.00e+00 ns snow-day_0.01 down-sample down-sample-ancestor 100 2.42e-01 1.00e+00 ns snow-day_0.01 down-sample indiv-rand-sample 100 1.00e+00 1.00e+00 ns snow-day_0.01 down-sample phylo-informed-sample 100 1.00e+00 1.00e+00 ns snow-day_0.01 down-sample-ancestor indiv-rand-sample 100 6.17e-01 1.00e+00 ns snow-day_0.01 down-sample-ancestor phylo-informed-sample 100 6.17e-01 1.00e+00 ns snow-day_0.01 indiv-rand-sample phylo-informed-sample 100 1.00e+00 1.00e+00 ns snow-day_0.1 down-sample down-sample-ancestor 100 1.00e+00 1.00e+00 ns snow-day_0.1 down-sample indiv-rand-sample 100 1.00e+00 1.00e+00 ns snow-day_0.1 down-sample phylo-informed-sample 100 1.17e-01 7.02e-01 ns snow-day_0.1 down-sample-ancestor indiv-rand-sample 100 1.00e+00 1.00e+00 ns snow-day_0.1 down-sample-ancestor phylo-informed-sample 100 1.17e-01 7.02e-01 ns snow-day_0.1 indiv-rand-sample phylo-informed-sample 100 3.62e-01 1.00e+00 ns 8.4 Average number of unique candidates selected full_avgs &lt;- ts_data %&gt;% filter(eval_label == &quot;full&quot;) %&gt;% group_by(PROBLEM) %&gt;% summarize( n = n(), median_num_unique_selected = median(num_unique_selected), median_entropy_selected_ids = median(entropy_selected_ids), avg_num_unique_selected = mean(num_unique_selected), avg_entropy_selected_ids = mean(entropy_selected_ids) ) build_plot_summary_data &lt;- function( data, response ) { plot &lt;- data %&gt;% filter( eval_label != &quot;full&quot; ) %&gt;% ggplot( aes_string( x = &quot;eval_label&quot;, y = response, fill = &quot;eval_label&quot; ) ) + geom_flat_violin( position = position_nudge(x = .2, y = 0), alpha = .8, adjust = 1.5 ) + geom_point( mapping = aes(color = eval_label), position = position_jitter(width = .15), size = .5, alpha = 0.8 ) + geom_boxplot( width = .1, outlier.shape = NA, alpha = 0.5 ) + scale_y_continuous( # limits = c(-0.5, 100) ) + scale_fill_bright() + scale_color_bright() + facet_grid( PROBLEM ~ evals_per_gen, # nrow=2, labeller = label_both ) + theme( legend.position = &quot;none&quot;, axis.text.x = element_text( angle = 30, hjust = 1 ), panel.border = element_rect(color = &quot;gray&quot;, size = 2) ) return(plot) } plt &lt;- build_plot_summary_data( ts_avgs, &quot;avg_num_unique_selected&quot; ) ggsave( filename = paste0(plot_directory, &quot;avg_num_unique_selected.pdf&quot;), plot = plt ) ## Saving 7 x 5 in image plt &lt;- build_plot_summary_data( ts_avgs, &quot;avg_entropy_selected_ids&quot; ) ggsave( filename = paste0(plot_directory, &quot;avg_entropy_selected_ids.pdf&quot;), plot = plt ) ## Saving 7 x 5 in image "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
